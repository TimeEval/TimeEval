{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SIGKDD21 multi-dataset time series anomaly detection (TSAD) competition\n",
    "\n",
    "- Source and description: https://compete.hexagon-ml.com/practice/competition/39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from config import data_raw_folder, data_processed_folder\n",
    "from timeeval import Datasets\n",
    "from timeeval.datasets import DatasetAnalyzer, DatasetRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_datasets(folder):\n",
    "    if not isinstance(folder, Path):\n",
    "        folder = Path(folder)\n",
    "    return sorted([f for f in folder.glob(\"*.txt\") if f.is_file()])\n",
    "\n",
    "def plot_dataset(f, with_split=True):\n",
    "    name = f.stem\n",
    "    split_at = int(name.split(\"_\")[-3])\n",
    "    anomaly = tuple(int(idx) for idx in name.split(\"_\")[-2:])\n",
    "    data = np.genfromtxt(f)\n",
    "    if with_split:\n",
    "        train = np.full_like(data, fill_value=np.nan)\n",
    "        train[:split_at] = data[:split_at]\n",
    "        test = np.full_like(data, fill_value=np.nan)\n",
    "        test[split_at:] = data[split_at:]\n",
    "        plt.plot(train, label=\"train\", color=\"red\")\n",
    "        plt.plot(test, label=\"test\", color=\"green\")\n",
    "    else:\n",
    "        plt.plot(data, label=name, color=\"black\")\n",
    "    # add anomaly label\n",
    "    plt.gca().add_patch(matplotlib.patches.Rectangle(\n",
    "        (anomaly[0], data.min()),\n",
    "        anomaly[1]-anomaly[0],\n",
    "        data.max()-data.min(),\n",
    "        color=\"yellow\", alpha=0.75\n",
    "    ))\n",
    "    plt.title(name)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for source datasets in /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-raw/UCR_TimeSeriesAnomalyDatasets2021/FilesAreInHere/UCR_Anomaly_FullData and\n",
      "saving processed datasets in /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed\n"
     ]
    }
   ],
   "source": [
    "dataset_collection_name = \"KDD-TSAD\"\n",
    "source_folder = Path(data_raw_folder) / \"UCR_TimeSeriesAnomalyDatasets2021\" / \"FilesAreInHere\" / \"UCR_Anomaly_FullData\"\n",
    "target_folder = Path(data_processed_folder)\n",
    "\n",
    "print(f\"Looking for source datasets in {Path(source_folder).absolute()} and\\nsaving processed datasets in {Path(target_folder).absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directories /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD\n"
     ]
    }
   ],
   "source": [
    "# shared by all datasets\n",
    "dataset_type = \"synthetic\"\n",
    "input_type = \"univariate\"\n",
    "datetime_index = False\n",
    "split_at = None\n",
    "train_is_normal = True\n",
    "train_type = \"semi-supervised\"\n",
    "\n",
    "# create target directory\n",
    "dataset_subfolder = Path(input_type) / dataset_collection_name\n",
    "target_subfolder = target_folder / dataset_subfolder\n",
    "target_subfolder.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Created directories {target_subfolder}\")\n",
    "\n",
    "dm = Datasets(target_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Processing source dataset 0\n",
      "  skipped writing dataset 0 to disk, because it already exists.\n",
      "  skipped analyzing dataset 0, because metadata already exists.\n",
      "... processed source dataset 0: 001_UCR_Anomaly_DISTORTED1sddb40_35000_52000_52620.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/001_UCR_Anomaly_DISTORTED1sddb40.test.csv\n",
      "> Processing source dataset 1\n",
      "  skipped writing dataset 1 to disk, because it already exists.\n",
      "  skipped analyzing dataset 1, because metadata already exists.\n",
      "... processed source dataset 1: 002_UCR_Anomaly_DISTORTED2sddb40_35000_56600_56900.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/002_UCR_Anomaly_DISTORTED2sddb40.test.csv\n",
      "> Processing source dataset 2\n",
      "  skipped writing dataset 2 to disk, because it already exists.\n",
      "  skipped analyzing dataset 2, because metadata already exists.\n",
      "... processed source dataset 2: 003_UCR_Anomaly_DISTORTED3sddb40_35000_46600_46900.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/003_UCR_Anomaly_DISTORTED3sddb40.test.csv\n",
      "> Processing source dataset 3\n",
      "  skipped writing dataset 3 to disk, because it already exists.\n",
      "  skipped analyzing dataset 3, because metadata already exists.\n",
      "... processed source dataset 3: 004_UCR_Anomaly_DISTORTEDBIDMC1_2500_5400_5600.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/004_UCR_Anomaly_DISTORTEDBIDMC1.test.csv\n",
      "> Processing source dataset 4\n",
      "  skipped writing dataset 4 to disk, because it already exists.\n",
      "  skipped analyzing dataset 4, because metadata already exists.\n",
      "... processed source dataset 4: 005_UCR_Anomaly_DISTORTEDCIMIS44AirTemperature1_4000_5391_5392.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/005_UCR_Anomaly_DISTORTEDCIMIS44AirTemperature1.test.csv\n",
      "> Processing source dataset 5\n",
      "  skipped writing dataset 5 to disk, because it already exists.\n",
      "  skipped analyzing dataset 5, because metadata already exists.\n",
      "... processed source dataset 5: 006_UCR_Anomaly_DISTORTEDCIMIS44AirTemperature2_4000_5703_5727.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/006_UCR_Anomaly_DISTORTEDCIMIS44AirTemperature2.test.csv\n",
      "> Processing source dataset 6\n",
      "  skipped writing dataset 6 to disk, because it already exists.\n",
      "  skipped analyzing dataset 6, because metadata already exists.\n",
      "... processed source dataset 6: 007_UCR_Anomaly_DISTORTEDCIMIS44AirTemperature3_4000_6520_6544.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/007_UCR_Anomaly_DISTORTEDCIMIS44AirTemperature3.test.csv\n",
      "> Processing source dataset 7\n",
      "  skipped writing dataset 7 to disk, because it already exists.\n",
      "  skipped analyzing dataset 7, because metadata already exists.\n",
      "... processed source dataset 7: 008_UCR_Anomaly_DISTORTEDCIMIS44AirTemperature4_4000_5549_5597.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/008_UCR_Anomaly_DISTORTEDCIMIS44AirTemperature4.test.csv\n",
      "> Processing source dataset 8\n",
      "  skipped writing dataset 8 to disk, because it already exists.\n",
      "  skipped analyzing dataset 8, because metadata already exists.\n",
      "... processed source dataset 8: 009_UCR_Anomaly_DISTORTEDCIMIS44AirTemperature5_4000_4852_4900.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/009_UCR_Anomaly_DISTORTEDCIMIS44AirTemperature5.test.csv\n",
      "> Processing source dataset 9\n",
      "  skipped writing dataset 9 to disk, because it already exists.\n",
      "  skipped analyzing dataset 9, because metadata already exists.\n",
      "... processed source dataset 9: 010_UCR_Anomaly_DISTORTEDCIMIS44AirTemperature6_4000_6006_6054.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/010_UCR_Anomaly_DISTORTEDCIMIS44AirTemperature6.test.csv\n",
      "> Processing source dataset 10\n",
      "  skipped writing dataset 10 to disk, because it already exists.\n",
      "  skipped analyzing dataset 10, because metadata already exists.\n",
      "... processed source dataset 10: 011_UCR_Anomaly_DISTORTEDECG1_10000_11800_12100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/011_UCR_Anomaly_DISTORTEDECG1.test.csv\n",
      "> Processing source dataset 11\n",
      "  skipped writing dataset 11 to disk, because it already exists.\n",
      "  skipped analyzing dataset 11, because metadata already exists.\n",
      "... processed source dataset 11: 012_UCR_Anomaly_DISTORTEDECG2_15000_16000_16100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/012_UCR_Anomaly_DISTORTEDECG2.test.csv\n",
      "> Processing source dataset 12\n",
      "  skipped writing dataset 12 to disk, because it already exists.\n",
      "  skipped analyzing dataset 12, because metadata already exists.\n",
      "... processed source dataset 12: 013_UCR_Anomaly_DISTORTEDECG3_15000_16000_16100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/013_UCR_Anomaly_DISTORTEDECG3.test.csv\n",
      "> Processing source dataset 13\n",
      "  skipped writing dataset 13 to disk, because it already exists.\n",
      "  skipped analyzing dataset 13, because metadata already exists.\n",
      "... processed source dataset 13: 014_UCR_Anomaly_DISTORTEDECG3_8000_17000_17100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/014_UCR_Anomaly_DISTORTEDECG3.test.csv\n",
      "> Processing source dataset 14\n",
      "  skipped writing dataset 14 to disk, because it already exists.\n",
      "  skipped analyzing dataset 14, because metadata already exists.\n",
      "... processed source dataset 14: 015_UCR_Anomaly_DISTORTEDECG4_5000_16800_17100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/015_UCR_Anomaly_DISTORTEDECG4.test.csv\n",
      "> Processing source dataset 15\n",
      "  skipped writing dataset 15 to disk, because it already exists.\n",
      "  skipped analyzing dataset 15, because metadata already exists.\n",
      "... processed source dataset 15: 016_UCR_Anomaly_DISTORTEDECG4_5000_16900_17100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/016_UCR_Anomaly_DISTORTEDECG4.test.csv\n",
      "> Processing source dataset 16\n",
      "  skipped writing dataset 16 to disk, because it already exists.\n",
      "  skipped analyzing dataset 16, because metadata already exists.\n",
      "... processed source dataset 16: 017_UCR_Anomaly_DISTORTEDECG4_5000_17000_17100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/017_UCR_Anomaly_DISTORTEDECG4.test.csv\n",
      "> Processing source dataset 17\n",
      "  skipped writing dataset 17 to disk, because it already exists.\n",
      "  skipped analyzing dataset 17, because metadata already exists.\n",
      "... processed source dataset 17: 018_UCR_Anomaly_DISTORTEDECG4_8000_17000_17100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/018_UCR_Anomaly_DISTORTEDECG4.test.csv\n",
      "> Processing source dataset 18\n",
      "  skipped writing dataset 18 to disk, because it already exists.\n",
      "  skipped analyzing dataset 18, because metadata already exists.\n",
      "... processed source dataset 18: 019_UCR_Anomaly_DISTORTEDGP711MarkerLFM5z1_5000_6168_6212.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/019_UCR_Anomaly_DISTORTEDGP711MarkerLFM5z1.test.csv\n",
      "> Processing source dataset 19\n",
      "  skipped writing dataset 19 to disk, because it already exists.\n",
      "  skipped analyzing dataset 19, because metadata already exists.\n",
      "... processed source dataset 19: 020_UCR_Anomaly_DISTORTEDGP711MarkerLFM5z2_5000_7175_7388.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/020_UCR_Anomaly_DISTORTEDGP711MarkerLFM5z2.test.csv\n",
      "> Processing source dataset 20\n",
      "  skipped writing dataset 20 to disk, because it already exists.\n",
      "  skipped analyzing dataset 20, because metadata already exists.\n",
      "... processed source dataset 20: 021_UCR_Anomaly_DISTORTEDGP711MarkerLFM5z3_5000_5948_5993.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/021_UCR_Anomaly_DISTORTEDGP711MarkerLFM5z3.test.csv\n",
      "> Processing source dataset 21\n",
      "  skipped writing dataset 21 to disk, because it already exists.\n",
      "  skipped analyzing dataset 21, because metadata already exists.\n",
      "... processed source dataset 21: 022_UCR_Anomaly_DISTORTEDGP711MarkerLFM5z4_4000_6527_6645.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/022_UCR_Anomaly_DISTORTEDGP711MarkerLFM5z4.test.csv\n",
      "> Processing source dataset 22\n",
      "  skipped writing dataset 22 to disk, because it already exists.\n",
      "  skipped analyzing dataset 22, because metadata already exists.\n",
      "... processed source dataset 22: 023_UCR_Anomaly_DISTORTEDGP711MarkerLFM5z5_5000_8612_8716.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/023_UCR_Anomaly_DISTORTEDGP711MarkerLFM5z5.test.csv\n",
      "> Processing source dataset 23\n",
      "  skipped writing dataset 23 to disk, because it already exists.\n",
      "  skipped analyzing dataset 23, because metadata already exists.\n",
      "... processed source dataset 23: 024_UCR_Anomaly_DISTORTEDInternalBleeding10_3200_4526_4556.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/024_UCR_Anomaly_DISTORTEDInternalBleeding10.test.csv\n",
      "> Processing source dataset 24\n",
      "  skipped writing dataset 24 to disk, because it already exists.\n",
      "  skipped analyzing dataset 24, because metadata already exists.\n",
      "... processed source dataset 24: 025_UCR_Anomaly_DISTORTEDInternalBleeding14_2800_5607_5634.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/025_UCR_Anomaly_DISTORTEDInternalBleeding14.test.csv\n",
      "> Processing source dataset 25\n",
      "  skipped writing dataset 25 to disk, because it already exists.\n",
      "  skipped analyzing dataset 25, because metadata already exists.\n",
      "... processed source dataset 25: 026_UCR_Anomaly_DISTORTEDInternalBleeding15_1700_5684_5854.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/026_UCR_Anomaly_DISTORTEDInternalBleeding15.test.csv\n",
      "> Processing source dataset 26\n",
      "  skipped writing dataset 26 to disk, because it already exists.\n",
      "  skipped analyzing dataset 26, because metadata already exists.\n",
      "... processed source dataset 26: 027_UCR_Anomaly_DISTORTEDInternalBleeding16_1200_4187_4199.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/027_UCR_Anomaly_DISTORTEDInternalBleeding16.test.csv\n",
      "> Processing source dataset 27\n",
      "  skipped writing dataset 27 to disk, because it already exists.\n",
      "  skipped analyzing dataset 27, because metadata already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... processed source dataset 27: 028_UCR_Anomaly_DISTORTEDInternalBleeding17_1600_3198_3309.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/028_UCR_Anomaly_DISTORTEDInternalBleeding17.test.csv\n",
      "> Processing source dataset 28\n",
      "  skipped writing dataset 28 to disk, because it already exists.\n",
      "  skipped analyzing dataset 28, because metadata already exists.\n",
      "... processed source dataset 28: 029_UCR_Anomaly_DISTORTEDInternalBleeding18_2300_4485_4587.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/029_UCR_Anomaly_DISTORTEDInternalBleeding18.test.csv\n",
      "> Processing source dataset 29\n",
      "  skipped writing dataset 29 to disk, because it already exists.\n",
      "  skipped analyzing dataset 29, because metadata already exists.\n",
      "... processed source dataset 29: 030_UCR_Anomaly_DISTORTEDInternalBleeding19_3000_4187_4197.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/030_UCR_Anomaly_DISTORTEDInternalBleeding19.test.csv\n",
      "> Processing source dataset 30\n",
      "  skipped writing dataset 30 to disk, because it already exists.\n",
      "  skipped analyzing dataset 30, because metadata already exists.\n",
      "... processed source dataset 30: 031_UCR_Anomaly_DISTORTEDInternalBleeding20_2700_5759_5919.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/031_UCR_Anomaly_DISTORTEDInternalBleeding20.test.csv\n",
      "> Processing source dataset 31\n",
      "  skipped writing dataset 31 to disk, because it already exists.\n",
      "  skipped analyzing dataset 31, because metadata already exists.\n",
      "... processed source dataset 31: 032_UCR_Anomaly_DISTORTEDInternalBleeding4_1000_4675_5033.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/032_UCR_Anomaly_DISTORTEDInternalBleeding4.test.csv\n",
      "> Processing source dataset 32\n",
      "  skipped writing dataset 32 to disk, because it already exists.\n",
      "  skipped analyzing dataset 32, because metadata already exists.\n",
      "... processed source dataset 32: 033_UCR_Anomaly_DISTORTEDInternalBleeding5_4000_6200_6370.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/033_UCR_Anomaly_DISTORTEDInternalBleeding5.test.csv\n",
      "> Processing source dataset 33\n",
      "  skipped writing dataset 33 to disk, because it already exists.\n",
      "  skipped analyzing dataset 33, because metadata already exists.\n",
      "... processed source dataset 33: 034_UCR_Anomaly_DISTORTEDInternalBleeding6_1500_3474_3629.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/034_UCR_Anomaly_DISTORTEDInternalBleeding6.test.csv\n",
      "> Processing source dataset 34\n",
      "  skipped writing dataset 34 to disk, because it already exists.\n",
      "  skipped analyzing dataset 34, because metadata already exists.\n",
      "... processed source dataset 34: 035_UCR_Anomaly_DISTORTEDInternalBleeding8_2500_5865_5974.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/035_UCR_Anomaly_DISTORTEDInternalBleeding8.test.csv\n",
      "> Processing source dataset 35\n",
      "  skipped writing dataset 35 to disk, because it already exists.\n",
      "  skipped analyzing dataset 35, because metadata already exists.\n",
      "... processed source dataset 35: 036_UCR_Anomaly_DISTORTEDInternalBleeding9_4200_6599_6681.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/036_UCR_Anomaly_DISTORTEDInternalBleeding9.test.csv\n",
      "> Processing source dataset 36\n",
      "  skipped writing dataset 36 to disk, because it already exists.\n",
      "  skipped analyzing dataset 36, because metadata already exists.\n",
      "... processed source dataset 36: 037_UCR_Anomaly_DISTORTEDLab2Cmac011215EPG1_5000_17210_17260.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/037_UCR_Anomaly_DISTORTEDLab2Cmac011215EPG1.test.csv\n",
      "> Processing source dataset 37\n",
      "  skipped writing dataset 37 to disk, because it already exists.\n",
      "  skipped analyzing dataset 37, because metadata already exists.\n",
      "... processed source dataset 37: 038_UCR_Anomaly_DISTORTEDLab2Cmac011215EPG2_5000_27862_27932.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/038_UCR_Anomaly_DISTORTEDLab2Cmac011215EPG2.test.csv\n",
      "> Processing source dataset 38\n",
      "  skipped writing dataset 38 to disk, because it already exists.\n",
      "  skipped analyzing dataset 38, because metadata already exists.\n",
      "... processed source dataset 38: 039_UCR_Anomaly_DISTORTEDLab2Cmac011215EPG3_5000_16390_16420.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/039_UCR_Anomaly_DISTORTEDLab2Cmac011215EPG3.test.csv\n",
      "> Processing source dataset 39\n",
      "  skipped writing dataset 39 to disk, because it already exists.\n",
      "  skipped analyzing dataset 39, because metadata already exists.\n",
      "... processed source dataset 39: 040_UCR_Anomaly_DISTORTEDLab2Cmac011215EPG4_6000_17390_17520.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/040_UCR_Anomaly_DISTORTEDLab2Cmac011215EPG4.test.csv\n",
      "> Processing source dataset 40\n",
      "  skipped writing dataset 40 to disk, because it already exists.\n",
      "  skipped analyzing dataset 40, because metadata already exists.\n",
      "... processed source dataset 40: 041_UCR_Anomaly_DISTORTEDLab2Cmac011215EPG5_7000_17390_17520.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/041_UCR_Anomaly_DISTORTEDLab2Cmac011215EPG5.test.csv\n",
      "> Processing source dataset 41\n",
      "  skipped writing dataset 41 to disk, because it already exists.\n",
      "  skipped analyzing dataset 41, because metadata already exists.\n",
      "... processed source dataset 41: 042_UCR_Anomaly_DISTORTEDLab2Cmac011215EPG6_7000_12190_12420.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/042_UCR_Anomaly_DISTORTEDLab2Cmac011215EPG6.test.csv\n",
      "> Processing source dataset 42\n",
      "  skipped writing dataset 42 to disk, because it already exists.\n",
      "  skipped analyzing dataset 42, because metadata already exists.\n",
      "... processed source dataset 42: 043_UCR_Anomaly_DISTORTEDMesoplodonDensirostris_10000_19280_19440.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/043_UCR_Anomaly_DISTORTEDMesoplodonDensirostris.test.csv\n",
      "> Processing source dataset 43\n",
      "  skipped writing dataset 43 to disk, because it already exists.\n",
      "  skipped analyzing dataset 43, because metadata already exists.\n",
      "... processed source dataset 43: 044_UCR_Anomaly_DISTORTEDPowerDemand1_9000_18485_18821.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/044_UCR_Anomaly_DISTORTEDPowerDemand1.test.csv\n",
      "> Processing source dataset 44\n",
      "  skipped writing dataset 44 to disk, because it already exists.\n",
      "  skipped analyzing dataset 44, because metadata already exists.\n",
      "... processed source dataset 44: 045_UCR_Anomaly_DISTORTEDPowerDemand2_14000_23357_23717.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/045_UCR_Anomaly_DISTORTEDPowerDemand2.test.csv\n",
      "> Processing source dataset 45\n",
      "  skipped writing dataset 45 to disk, because it already exists.\n",
      "  skipped analyzing dataset 45, because metadata already exists.\n",
      "... processed source dataset 45: 046_UCR_Anomaly_DISTORTEDPowerDemand3_16000_23405_23477.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/046_UCR_Anomaly_DISTORTEDPowerDemand3.test.csv\n",
      "> Processing source dataset 46\n",
      "  skipped writing dataset 46 to disk, because it already exists.\n",
      "  skipped analyzing dataset 46, because metadata already exists.\n",
      "... processed source dataset 46: 047_UCR_Anomaly_DISTORTEDPowerDemand4_18000_24005_24077.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/047_UCR_Anomaly_DISTORTEDPowerDemand4.test.csv\n",
      "> Processing source dataset 47\n",
      "  skipped writing dataset 47 to disk, because it already exists.\n",
      "  skipped analyzing dataset 47, because metadata already exists.\n",
      "... processed source dataset 47: 048_UCR_Anomaly_DISTORTEDTkeepFifthMARS_3500_5988_6085.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/048_UCR_Anomaly_DISTORTEDTkeepFifthMARS.test.csv\n",
      "> Processing source dataset 48\n",
      "  skipped writing dataset 48 to disk, because it already exists.\n",
      "  skipped analyzing dataset 48, because metadata already exists.\n",
      "... processed source dataset 48: 049_UCR_Anomaly_DISTORTEDTkeepFirstMARS_3500_5365_5380.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/049_UCR_Anomaly_DISTORTEDTkeepFirstMARS.test.csv\n",
      "> Processing source dataset 49\n",
      "  skipped writing dataset 49 to disk, because it already exists.\n",
      "  skipped analyzing dataset 49, because metadata already exists.\n",
      "... processed source dataset 49: 050_UCR_Anomaly_DISTORTEDTkeepForthMARS_3500_5988_6085.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/050_UCR_Anomaly_DISTORTEDTkeepForthMARS.test.csv\n",
      "> Processing source dataset 50\n",
      "  skipped writing dataset 50 to disk, because it already exists.\n",
      "  skipped analyzing dataset 50, because metadata already exists.\n",
      "... processed source dataset 50: 051_UCR_Anomaly_DISTORTEDTkeepSecondMARS_3500_9330_9340.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/051_UCR_Anomaly_DISTORTEDTkeepSecondMARS.test.csv\n",
      "> Processing source dataset 51\n",
      "  skipped writing dataset 51 to disk, because it already exists.\n",
      "  skipped analyzing dataset 51, because metadata already exists.\n",
      "... processed source dataset 51: 052_UCR_Anomaly_DISTORTEDTkeepThirdMARS_3500_4711_4809.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/052_UCR_Anomaly_DISTORTEDTkeepThirdMARS.test.csv\n",
      "> Processing source dataset 52\n",
      "  skipped writing dataset 52 to disk, because it already exists.\n",
      "  skipped analyzing dataset 52, because metadata already exists.\n",
      "... processed source dataset 52: 053_UCR_Anomaly_DISTORTEDWalkingAceleration1_1500_2764_2995.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/053_UCR_Anomaly_DISTORTEDWalkingAceleration1.test.csv\n",
      "> Processing source dataset 53\n",
      "  skipped writing dataset 53 to disk, because it already exists.\n",
      "  skipped analyzing dataset 53, because metadata already exists.\n",
      "... processed source dataset 53: 054_UCR_Anomaly_DISTORTEDWalkingAceleration5_2700_5920_5979.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/054_UCR_Anomaly_DISTORTEDWalkingAceleration5.test.csv\n",
      "> Processing source dataset 54\n",
      "  skipped writing dataset 54 to disk, because it already exists.\n",
      "  skipped analyzing dataset 54, because metadata already exists.\n",
      "... processed source dataset 54: 055_UCR_Anomaly_DISTORTEDapneaecg2_10000_20950_21100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/055_UCR_Anomaly_DISTORTEDapneaecg2.test.csv\n",
      "> Processing source dataset 55\n",
      "  skipped writing dataset 55 to disk, because it already exists.\n",
      "  skipped analyzing dataset 55, because metadata already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... processed source dataset 55: 056_UCR_Anomaly_DISTORTEDapneaecg3_5000_11111_11211.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/056_UCR_Anomaly_DISTORTEDapneaecg3.test.csv\n",
      "> Processing source dataset 56\n",
      "  skipped writing dataset 56 to disk, because it already exists.\n",
      "  skipped analyzing dataset 56, because metadata already exists.\n",
      "... processed source dataset 56: 057_UCR_Anomaly_DISTORTEDapneaecg4_6000_16000_16100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/057_UCR_Anomaly_DISTORTEDapneaecg4.test.csv\n",
      "> Processing source dataset 57\n",
      "  skipped writing dataset 57 to disk, because it already exists.\n",
      "  skipped analyzing dataset 57, because metadata already exists.\n",
      "... processed source dataset 57: 058_UCR_Anomaly_DISTORTEDapneaecg_10000_12240_12308.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/058_UCR_Anomaly_DISTORTEDapneaecg.test.csv\n",
      "> Processing source dataset 58\n",
      "  skipped writing dataset 58 to disk, because it already exists.\n",
      "  skipped analyzing dataset 58, because metadata already exists.\n",
      "... processed source dataset 58: 059_UCR_Anomaly_DISTORTEDgait1_20000_38500_38800.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/059_UCR_Anomaly_DISTORTEDgait1.test.csv\n",
      "> Processing source dataset 59\n",
      "  skipped writing dataset 59 to disk, because it already exists.\n",
      "  skipped analyzing dataset 59, because metadata already exists.\n",
      "... processed source dataset 59: 060_UCR_Anomaly_DISTORTEDgait2_22000_46500_46800.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/060_UCR_Anomaly_DISTORTEDgait2.test.csv\n",
      "> Processing source dataset 60\n",
      "  skipped writing dataset 60 to disk, because it already exists.\n",
      "  skipped analyzing dataset 60, because metadata already exists.\n",
      "... processed source dataset 60: 061_UCR_Anomaly_DISTORTEDgait3_24500_59900_60500.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/061_UCR_Anomaly_DISTORTEDgait3.test.csv\n",
      "> Processing source dataset 61\n",
      "  skipped writing dataset 61 to disk, because it already exists.\n",
      "  skipped analyzing dataset 61, because metadata already exists.\n",
      "... processed source dataset 61: 062_UCR_Anomaly_DISTORTEDgaitHunt1_18500_33070_33180.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/062_UCR_Anomaly_DISTORTEDgaitHunt1.test.csv\n",
      "> Processing source dataset 62\n",
      "  skipped writing dataset 62 to disk, because it already exists.\n",
      "  skipped analyzing dataset 62, because metadata already exists.\n",
      "... processed source dataset 62: 063_UCR_Anomaly_DISTORTEDgaitHunt2_18500_31200_31850.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/063_UCR_Anomaly_DISTORTEDgaitHunt2.test.csv\n",
      "> Processing source dataset 63\n",
      "  skipped writing dataset 63 to disk, because it already exists.\n",
      "  skipped analyzing dataset 63, because metadata already exists.\n",
      "... processed source dataset 63: 064_UCR_Anomaly_DISTORTEDgaitHunt3_23400_38400_39200.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/064_UCR_Anomaly_DISTORTEDgaitHunt3.test.csv\n",
      "> Processing source dataset 64\n",
      "  skipped writing dataset 64 to disk, because it already exists.\n",
      "  skipped analyzing dataset 64, because metadata already exists.\n",
      "... processed source dataset 64: 065_UCR_Anomaly_DISTORTEDinsectEPG1_3000_7000_7030.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/065_UCR_Anomaly_DISTORTEDinsectEPG1.test.csv\n",
      "> Processing source dataset 65\n",
      "  skipped writing dataset 65 to disk, because it already exists.\n",
      "  skipped analyzing dataset 65, because metadata already exists.\n",
      "... processed source dataset 65: 066_UCR_Anomaly_DISTORTEDinsectEPG2_3700_8000_8025.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/066_UCR_Anomaly_DISTORTEDinsectEPG2.test.csv\n",
      "> Processing source dataset 66\n",
      "  skipped writing dataset 66 to disk, because it already exists.\n",
      "  skipped analyzing dataset 66, because metadata already exists.\n",
      "... processed source dataset 66: 067_UCR_Anomaly_DISTORTEDinsectEPG3_5200_7000_7050.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/067_UCR_Anomaly_DISTORTEDinsectEPG3.test.csv\n",
      "> Processing source dataset 67\n",
      "  skipped writing dataset 67 to disk, because it already exists.\n",
      "  skipped analyzing dataset 67, because metadata already exists.\n",
      "... processed source dataset 67: 068_UCR_Anomaly_DISTORTEDinsectEPG4_1300_6508_6558.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/068_UCR_Anomaly_DISTORTEDinsectEPG4.test.csv\n",
      "> Processing source dataset 68\n",
      "  skipped writing dataset 68 to disk, because it already exists.\n",
      "  skipped analyzing dataset 68, because metadata already exists.\n",
      "... processed source dataset 68: 069_UCR_Anomaly_DISTORTEDinsectEPG5_3200_8500_8501.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/069_UCR_Anomaly_DISTORTEDinsectEPG5.test.csv\n",
      "> Processing source dataset 69\n",
      "  skipped writing dataset 69 to disk, because it already exists.\n",
      "  skipped analyzing dataset 69, because metadata already exists.\n",
      "... processed source dataset 69: 070_UCR_Anomaly_DISTORTEDltstdbs30791AI_17555_52600_52800.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/070_UCR_Anomaly_DISTORTEDltstdbs30791AI.test.csv\n",
      "> Processing source dataset 70\n",
      "  skipped writing dataset 70 to disk, because it already exists.\n",
      "  skipped analyzing dataset 70, because metadata already exists.\n",
      "... processed source dataset 70: 071_UCR_Anomaly_DISTORTEDltstdbs30791AS_23000_52600_52800.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/071_UCR_Anomaly_DISTORTEDltstdbs30791AS.test.csv\n",
      "> Processing source dataset 71\n",
      "  skipped writing dataset 71 to disk, because it already exists.\n",
      "  skipped analyzing dataset 71, because metadata already exists.\n",
      "... processed source dataset 71: 072_UCR_Anomaly_DISTORTEDltstdbs30791ES_20000_52600_52800.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/072_UCR_Anomaly_DISTORTEDltstdbs30791ES.test.csv\n",
      "> Processing source dataset 72\n",
      "  skipped writing dataset 72 to disk, because it already exists.\n",
      "  skipped analyzing dataset 72, because metadata already exists.\n",
      "... processed source dataset 72: 073_UCR_Anomaly_DISTORTEDpark3m_60000_72150_72495.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/073_UCR_Anomaly_DISTORTEDpark3m.test.csv\n",
      "> Processing source dataset 73\n",
      "  skipped writing dataset 73 to disk, because it already exists.\n",
      "  skipped analyzing dataset 73, because metadata already exists.\n",
      "... processed source dataset 73: 074_UCR_Anomaly_DISTORTEDqtdbSel1005V_4000_12400_12800.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/074_UCR_Anomaly_DISTORTEDqtdbSel1005V.test.csv\n",
      "> Processing source dataset 74\n",
      "  skipped writing dataset 74 to disk, because it already exists.\n",
      "  skipped analyzing dataset 74, because metadata already exists.\n",
      "... processed source dataset 74: 075_UCR_Anomaly_DISTORTEDqtdbSel100MLII_4000_13400_13800.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/075_UCR_Anomaly_DISTORTEDqtdbSel100MLII.test.csv\n",
      "> Processing source dataset 75\n",
      "  skipped writing dataset 75 to disk, because it already exists.\n",
      "  skipped analyzing dataset 75, because metadata already exists.\n",
      "... processed source dataset 75: 076_UCR_Anomaly_DISTORTEDresperation10_48000_130700_131880.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/076_UCR_Anomaly_DISTORTEDresperation10.test.csv\n",
      "> Processing source dataset 76\n",
      "  skipped writing dataset 76 to disk, because it already exists.\n",
      "  skipped analyzing dataset 76, because metadata already exists.\n",
      "... processed source dataset 76: 077_UCR_Anomaly_DISTORTEDresperation11_58000_110800_110801.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/077_UCR_Anomaly_DISTORTEDresperation11.test.csv\n",
      "> Processing source dataset 77\n",
      "  skipped writing dataset 77 to disk, because it already exists.\n",
      "  skipped analyzing dataset 77, because metadata already exists.\n",
      "... processed source dataset 77: 078_UCR_Anomaly_DISTORTEDresperation1_100000_110260_110412.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/078_UCR_Anomaly_DISTORTEDresperation1.test.csv\n",
      "> Processing source dataset 78\n",
      "  skipped writing dataset 78 to disk, because it already exists.\n",
      "  skipped analyzing dataset 78, because metadata already exists.\n",
      "... processed source dataset 78: 079_UCR_Anomaly_DISTORTEDresperation2_30000_168250_168250.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/079_UCR_Anomaly_DISTORTEDresperation2.test.csv\n",
      "> Processing source dataset 79\n",
      "  skipped writing dataset 79 to disk, because it already exists.\n",
      "  skipped analyzing dataset 79, because metadata already exists.\n",
      "... processed source dataset 79: 080_UCR_Anomaly_DISTORTEDresperation2_30000_168250_168251.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/080_UCR_Anomaly_DISTORTEDresperation2.test.csv\n",
      "> Processing source dataset 80\n",
      "  skipped writing dataset 80 to disk, because it already exists.\n",
      "  skipped analyzing dataset 80, because metadata already exists.\n",
      "... processed source dataset 80: 081_UCR_Anomaly_DISTORTEDresperation3_45000_158250_158251.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/081_UCR_Anomaly_DISTORTEDresperation3.test.csv\n",
      "> Processing source dataset 81\n",
      "  skipped writing dataset 81 to disk, because it already exists.\n",
      "  skipped analyzing dataset 81, because metadata already exists.\n",
      "... processed source dataset 81: 082_UCR_Anomaly_DISTORTEDresperation4_70000_128430_128431.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/082_UCR_Anomaly_DISTORTEDresperation4.test.csv\n",
      "> Processing source dataset 82\n",
      "  skipped writing dataset 82 to disk, because it already exists.\n",
      "  skipped analyzing dataset 82, because metadata already exists.\n",
      "... processed source dataset 82: 083_UCR_Anomaly_DISTORTEDresperation9_38000_143411_143511.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/083_UCR_Anomaly_DISTORTEDresperation9.test.csv\n",
      "> Processing source dataset 83\n",
      "  skipped writing dataset 83 to disk, because it already exists.\n",
      "  skipped analyzing dataset 83, because metadata already exists.\n",
      "... processed source dataset 83: 084_UCR_Anomaly_DISTORTEDs20101mML2_12000_35774_35874.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/084_UCR_Anomaly_DISTORTEDs20101mML2.test.csv\n",
      "> Processing source dataset 84\n",
      "  skipped writing dataset 84 to disk, because it already exists.\n",
      "  skipped analyzing dataset 84, because metadata already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... processed source dataset 84: 085_UCR_Anomaly_DISTORTEDs20101m_10000_35774_35874.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/085_UCR_Anomaly_DISTORTEDs20101m.test.csv\n",
      "> Processing source dataset 85\n",
      "  skipped writing dataset 85 to disk, because it already exists.\n",
      "  skipped analyzing dataset 85, because metadata already exists.\n",
      "... processed source dataset 85: 086_UCR_Anomaly_DISTORTEDsddb49_20000_67950_68200.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/086_UCR_Anomaly_DISTORTEDsddb49.test.csv\n",
      "> Processing source dataset 86\n",
      "  skipped writing dataset 86 to disk, because it already exists.\n",
      "  skipped analyzing dataset 86, because metadata already exists.\n",
      "... processed source dataset 86: 087_UCR_Anomaly_DISTORTEDsel840mECG1_17000_51370_51740.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/087_UCR_Anomaly_DISTORTEDsel840mECG1.test.csv\n",
      "> Processing source dataset 87\n",
      "  skipped writing dataset 87 to disk, because it already exists.\n",
      "  skipped analyzing dataset 87, because metadata already exists.\n",
      "... processed source dataset 87: 088_UCR_Anomaly_DISTORTEDsel840mECG2_20000_49370_49740.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/088_UCR_Anomaly_DISTORTEDsel840mECG2.test.csv\n",
      "> Processing source dataset 88\n",
      "  skipped writing dataset 88 to disk, because it already exists.\n",
      "  skipped analyzing dataset 88, because metadata already exists.\n",
      "... processed source dataset 88: 089_UCR_Anomaly_DISTORTEDtiltAPB1_100000_114283_114350.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/089_UCR_Anomaly_DISTORTEDtiltAPB1.test.csv\n",
      "> Processing source dataset 89\n",
      "  skipped writing dataset 89 to disk, because it already exists.\n",
      "  skipped analyzing dataset 89, because metadata already exists.\n",
      "... processed source dataset 89: 090_UCR_Anomaly_DISTORTEDtiltAPB2_50000_124159_124985.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/090_UCR_Anomaly_DISTORTEDtiltAPB2.test.csv\n",
      "> Processing source dataset 90\n",
      "  skipped writing dataset 90 to disk, because it already exists.\n",
      "  skipped analyzing dataset 90, because metadata already exists.\n",
      "... processed source dataset 90: 091_UCR_Anomaly_DISTORTEDtiltAPB3_40000_114000_114370.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/091_UCR_Anomaly_DISTORTEDtiltAPB3.test.csv\n",
      "> Processing source dataset 91\n",
      "  skipped writing dataset 91 to disk, because it already exists.\n",
      "  skipped analyzing dataset 91, because metadata already exists.\n",
      "... processed source dataset 91: 092_UCR_Anomaly_DISTORTEDtiltAPB4_20000_67995_67996.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/092_UCR_Anomaly_DISTORTEDtiltAPB4.test.csv\n",
      "> Processing source dataset 92\n",
      "  skipped writing dataset 92 to disk, because it already exists.\n",
      "  skipped analyzing dataset 92, because metadata already exists.\n",
      "... processed source dataset 92: 093_UCR_Anomaly_NOISE1sddb40_35000_52000_52620.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/093_UCR_Anomaly_NOISE1sddb40.test.csv\n",
      "> Processing source dataset 93\n",
      "  skipped writing dataset 93 to disk, because it already exists.\n",
      "  skipped analyzing dataset 93, because metadata already exists.\n",
      "... processed source dataset 93: 094_UCR_Anomaly_NOISEBIDMC1_2500_5400_5600.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/094_UCR_Anomaly_NOISEBIDMC1.test.csv\n",
      "> Processing source dataset 94\n",
      "  skipped writing dataset 94 to disk, because it already exists.\n",
      "  skipped analyzing dataset 94, because metadata already exists.\n",
      "... processed source dataset 94: 095_UCR_Anomaly_NOISECIMIS44AirTemperature4_4000_5549_5597.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/095_UCR_Anomaly_NOISECIMIS44AirTemperature4.test.csv\n",
      "> Processing source dataset 95\n",
      "  skipped writing dataset 95 to disk, because it already exists.\n",
      "  skipped analyzing dataset 95, because metadata already exists.\n",
      "... processed source dataset 95: 096_UCR_Anomaly_NOISEECG4_5000_16900_17100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/096_UCR_Anomaly_NOISEECG4.test.csv\n",
      "> Processing source dataset 96\n",
      "  skipped writing dataset 96 to disk, because it already exists.\n",
      "  skipped analyzing dataset 96, because metadata already exists.\n",
      "... processed source dataset 96: 097_UCR_Anomaly_NOISEGP711MarkerLFM5z3_5000_5948_5993.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/097_UCR_Anomaly_NOISEGP711MarkerLFM5z3.test.csv\n",
      "> Processing source dataset 97\n",
      "  skipped writing dataset 97 to disk, because it already exists.\n",
      "  skipped analyzing dataset 97, because metadata already exists.\n",
      "... processed source dataset 97: 098_UCR_Anomaly_NOISEInternalBleeding16_1200_4187_4199.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/098_UCR_Anomaly_NOISEInternalBleeding16.test.csv\n",
      "> Processing source dataset 98\n",
      "  skipped writing dataset 98 to disk, because it already exists.\n",
      "  skipped analyzing dataset 98, because metadata already exists.\n",
      "... processed source dataset 98: 099_UCR_Anomaly_NOISEInternalBleeding6_1500_3474_3629.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/099_UCR_Anomaly_NOISEInternalBleeding6.test.csv\n",
      "> Processing source dataset 99\n",
      "  skipped writing dataset 99 to disk, because it already exists.\n",
      "  skipped analyzing dataset 99, because metadata already exists.\n",
      "... processed source dataset 99: 100_UCR_Anomaly_NOISELab2Cmac011215EPG1_5000_17210_17260.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/100_UCR_Anomaly_NOISELab2Cmac011215EPG1.test.csv\n",
      "> Processing source dataset 100\n",
      "  skipped writing dataset 100 to disk, because it already exists.\n",
      "  skipped analyzing dataset 100, because metadata already exists.\n",
      "... processed source dataset 100: 101_UCR_Anomaly_NOISELab2Cmac011215EPG4_6000_17390_17520.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/101_UCR_Anomaly_NOISELab2Cmac011215EPG4.test.csv\n",
      "> Processing source dataset 101\n",
      "  skipped writing dataset 101 to disk, because it already exists.\n",
      "  skipped analyzing dataset 101, because metadata already exists.\n",
      "... processed source dataset 101: 102_UCR_Anomaly_NOISEMesoplodonDensirostris_10000_19280_19440.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/102_UCR_Anomaly_NOISEMesoplodonDensirostris.test.csv\n",
      "> Processing source dataset 102\n",
      "  skipped writing dataset 102 to disk, because it already exists.\n",
      "  skipped analyzing dataset 102, because metadata already exists.\n",
      "... processed source dataset 102: 103_UCR_Anomaly_NOISETkeepThirdMARS_3500_4711_4809.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/103_UCR_Anomaly_NOISETkeepThirdMARS.test.csv\n",
      "> Processing source dataset 103\n",
      "  skipped writing dataset 103 to disk, because it already exists.\n",
      "  skipped analyzing dataset 103, because metadata already exists.\n",
      "... processed source dataset 103: 104_UCR_Anomaly_NOISEapneaecg4_6000_16000_16100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/104_UCR_Anomaly_NOISEapneaecg4.test.csv\n",
      "> Processing source dataset 104\n",
      "  skipped writing dataset 104 to disk, because it already exists.\n",
      "  skipped analyzing dataset 104, because metadata already exists.\n",
      "... processed source dataset 104: 105_UCR_Anomaly_NOISEgait3_24500_59900_60500.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/105_UCR_Anomaly_NOISEgait3.test.csv\n",
      "> Processing source dataset 105\n",
      "  skipped writing dataset 105 to disk, because it already exists.\n",
      "  skipped analyzing dataset 105, because metadata already exists.\n",
      "... processed source dataset 105: 106_UCR_Anomaly_NOISEgaitHunt2_18500_31200_31850.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/106_UCR_Anomaly_NOISEgaitHunt2.test.csv\n",
      "> Processing source dataset 106\n",
      "  skipped writing dataset 106 to disk, because it already exists.\n",
      "  skipped analyzing dataset 106, because metadata already exists.\n",
      "... processed source dataset 106: 107_UCR_Anomaly_NOISEinsectEPG3_5200_7000_7050.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/107_UCR_Anomaly_NOISEinsectEPG3.test.csv\n",
      "> Processing source dataset 107\n",
      "  skipped writing dataset 107 to disk, because it already exists.\n",
      "  skipped analyzing dataset 107, because metadata already exists.\n",
      "... processed source dataset 107: 108_UCR_Anomaly_NOISEresperation2_30000_168250_168250.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/108_UCR_Anomaly_NOISEresperation2.test.csv\n",
      "> Processing source dataset 108\n",
      "  skipped writing dataset 108 to disk, because it already exists.\n",
      "  skipped analyzing dataset 108, because metadata already exists.\n",
      "... processed source dataset 108: 109_UCR_Anomaly_1sddb40_35000_52000_52620.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/109_UCR_Anomaly_1sddb40.test.csv\n",
      "> Processing source dataset 109\n",
      "  skipped writing dataset 109 to disk, because it already exists.\n",
      "  skipped analyzing dataset 109, because metadata already exists.\n",
      "... processed source dataset 109: 110_UCR_Anomaly_2sddb40_35000_56600_56900.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/110_UCR_Anomaly_2sddb40.test.csv\n",
      "> Processing source dataset 110\n",
      "  skipped writing dataset 110 to disk, because it already exists.\n",
      "  skipped analyzing dataset 110, because metadata already exists.\n",
      "... processed source dataset 110: 111_UCR_Anomaly_3sddb40_35000_46600_46900.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/111_UCR_Anomaly_3sddb40.test.csv\n",
      "> Processing source dataset 111\n",
      "  skipped writing dataset 111 to disk, because it already exists.\n",
      "  skipped analyzing dataset 111, because metadata already exists.\n",
      "... processed source dataset 111: 112_UCR_Anomaly_BIDMC1_2500_5400_5600.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/112_UCR_Anomaly_BIDMC1.test.csv\n",
      "> Processing source dataset 112\n",
      "  skipped writing dataset 112 to disk, because it already exists.\n",
      "  skipped analyzing dataset 112, because metadata already exists.\n",
      "... processed source dataset 112: 113_UCR_Anomaly_CIMIS44AirTemperature1_4000_5391_5392.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/113_UCR_Anomaly_CIMIS44AirTemperature1.test.csv\n",
      "> Processing source dataset 113\n",
      "  skipped writing dataset 113 to disk, because it already exists.\n",
      "  skipped analyzing dataset 113, because metadata already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... processed source dataset 113: 114_UCR_Anomaly_CIMIS44AirTemperature2_4000_5703_5727.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/114_UCR_Anomaly_CIMIS44AirTemperature2.test.csv\n",
      "> Processing source dataset 114\n",
      "  skipped writing dataset 114 to disk, because it already exists.\n",
      "  skipped analyzing dataset 114, because metadata already exists.\n",
      "... processed source dataset 114: 115_UCR_Anomaly_CIMIS44AirTemperature3_4000_6520_6544.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/115_UCR_Anomaly_CIMIS44AirTemperature3.test.csv\n",
      "> Processing source dataset 115\n",
      "  skipped writing dataset 115 to disk, because it already exists.\n",
      "  skipped analyzing dataset 115, because metadata already exists.\n",
      "... processed source dataset 115: 116_UCR_Anomaly_CIMIS44AirTemperature4_4000_5549_5597.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/116_UCR_Anomaly_CIMIS44AirTemperature4.test.csv\n",
      "> Processing source dataset 116\n",
      "  skipped writing dataset 116 to disk, because it already exists.\n",
      "  skipped analyzing dataset 116, because metadata already exists.\n",
      "... processed source dataset 116: 117_UCR_Anomaly_CIMIS44AirTemperature5_4000_4852_4900.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/117_UCR_Anomaly_CIMIS44AirTemperature5.test.csv\n",
      "> Processing source dataset 117\n",
      "  skipped writing dataset 117 to disk, because it already exists.\n",
      "  skipped analyzing dataset 117, because metadata already exists.\n",
      "... processed source dataset 117: 118_UCR_Anomaly_CIMIS44AirTemperature6_4000_6006_6054.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/118_UCR_Anomaly_CIMIS44AirTemperature6.test.csv\n",
      "> Processing source dataset 118\n",
      "  skipped writing dataset 118 to disk, because it already exists.\n",
      "  skipped analyzing dataset 118, because metadata already exists.\n",
      "... processed source dataset 118: 119_UCR_Anomaly_ECG1_10000_11800_12100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/119_UCR_Anomaly_ECG1.test.csv\n",
      "> Processing source dataset 119\n",
      "  skipped writing dataset 119 to disk, because it already exists.\n",
      "  skipped analyzing dataset 119, because metadata already exists.\n",
      "... processed source dataset 119: 120_UCR_Anomaly_ECG2_15000_16000_16100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/120_UCR_Anomaly_ECG2.test.csv\n",
      "> Processing source dataset 120\n",
      "  skipped writing dataset 120 to disk, because it already exists.\n",
      "  skipped analyzing dataset 120, because metadata already exists.\n",
      "... processed source dataset 120: 121_UCR_Anomaly_ECG3_15000_16000_16100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/121_UCR_Anomaly_ECG3.test.csv\n",
      "> Processing source dataset 121\n",
      "  skipped writing dataset 121 to disk, because it already exists.\n",
      "  skipped analyzing dataset 121, because metadata already exists.\n",
      "... processed source dataset 121: 122_UCR_Anomaly_ECG3_8000_17000_17100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/122_UCR_Anomaly_ECG3.test.csv\n",
      "> Processing source dataset 122\n",
      "  skipped writing dataset 122 to disk, because it already exists.\n",
      "  skipped analyzing dataset 122, because metadata already exists.\n",
      "... processed source dataset 122: 123_UCR_Anomaly_ECG4_5000_16800_17100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/123_UCR_Anomaly_ECG4.test.csv\n",
      "> Processing source dataset 123\n",
      "  skipped writing dataset 123 to disk, because it already exists.\n",
      "  skipped analyzing dataset 123, because metadata already exists.\n",
      "... processed source dataset 123: 124_UCR_Anomaly_ECG4_5000_16900_17100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/124_UCR_Anomaly_ECG4.test.csv\n",
      "> Processing source dataset 124\n",
      "  skipped writing dataset 124 to disk, because it already exists.\n",
      "  skipped analyzing dataset 124, because metadata already exists.\n",
      "... processed source dataset 124: 125_UCR_Anomaly_ECG4_5000_17000_17100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/125_UCR_Anomaly_ECG4.test.csv\n",
      "> Processing source dataset 125\n",
      "  skipped writing dataset 125 to disk, because it already exists.\n",
      "  skipped analyzing dataset 125, because metadata already exists.\n",
      "... processed source dataset 125: 126_UCR_Anomaly_ECG4_8000_17000_17100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/126_UCR_Anomaly_ECG4.test.csv\n",
      "> Processing source dataset 126\n",
      "  skipped writing dataset 126 to disk, because it already exists.\n",
      "  skipped analyzing dataset 126, because metadata already exists.\n",
      "... processed source dataset 126: 127_UCR_Anomaly_GP711MarkerLFM5z1_5000_6168_6212.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/127_UCR_Anomaly_GP711MarkerLFM5z1.test.csv\n",
      "> Processing source dataset 127\n",
      "  skipped writing dataset 127 to disk, because it already exists.\n",
      "  skipped analyzing dataset 127, because metadata already exists.\n",
      "... processed source dataset 127: 128_UCR_Anomaly_GP711MarkerLFM5z2_5000_7175_7388.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/128_UCR_Anomaly_GP711MarkerLFM5z2.test.csv\n",
      "> Processing source dataset 128\n",
      "  skipped writing dataset 128 to disk, because it already exists.\n",
      "  skipped analyzing dataset 128, because metadata already exists.\n",
      "... processed source dataset 128: 129_UCR_Anomaly_GP711MarkerLFM5z3_5000_5948_5993.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/129_UCR_Anomaly_GP711MarkerLFM5z3.test.csv\n",
      "> Processing source dataset 129\n",
      "  skipped writing dataset 129 to disk, because it already exists.\n",
      "  skipped analyzing dataset 129, because metadata already exists.\n",
      "... processed source dataset 129: 130_UCR_Anomaly_GP711MarkerLFM5z4_4000_6527_6645.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/130_UCR_Anomaly_GP711MarkerLFM5z4.test.csv\n",
      "> Processing source dataset 130\n",
      "  skipped writing dataset 130 to disk, because it already exists.\n",
      "  skipped analyzing dataset 130, because metadata already exists.\n",
      "... processed source dataset 130: 131_UCR_Anomaly_GP711MarkerLFM5z5_5000_8612_8716.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/131_UCR_Anomaly_GP711MarkerLFM5z5.test.csv\n",
      "> Processing source dataset 131\n",
      "  skipped writing dataset 131 to disk, because it already exists.\n",
      "  skipped analyzing dataset 131, because metadata already exists.\n",
      "... processed source dataset 131: 132_UCR_Anomaly_InternalBleeding10_3200_4526_4556.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/132_UCR_Anomaly_InternalBleeding10.test.csv\n",
      "> Processing source dataset 132\n",
      "  skipped writing dataset 132 to disk, because it already exists.\n",
      "  skipped analyzing dataset 132, because metadata already exists.\n",
      "... processed source dataset 132: 133_UCR_Anomaly_InternalBleeding14_2800_5607_5634.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/133_UCR_Anomaly_InternalBleeding14.test.csv\n",
      "> Processing source dataset 133\n",
      "  skipped writing dataset 133 to disk, because it already exists.\n",
      "  skipped analyzing dataset 133, because metadata already exists.\n",
      "... processed source dataset 133: 134_UCR_Anomaly_InternalBleeding15_1700_5684_5854.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/134_UCR_Anomaly_InternalBleeding15.test.csv\n",
      "> Processing source dataset 134\n",
      "  skipped writing dataset 134 to disk, because it already exists.\n",
      "  skipped analyzing dataset 134, because metadata already exists.\n",
      "... processed source dataset 134: 135_UCR_Anomaly_InternalBleeding16_1200_4187_4199.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/135_UCR_Anomaly_InternalBleeding16.test.csv\n",
      "> Processing source dataset 135\n",
      "  skipped writing dataset 135 to disk, because it already exists.\n",
      "  skipped analyzing dataset 135, because metadata already exists.\n",
      "... processed source dataset 135: 136_UCR_Anomaly_InternalBleeding17_1600_3198_3309.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/136_UCR_Anomaly_InternalBleeding17.test.csv\n",
      "> Processing source dataset 136\n",
      "  skipped writing dataset 136 to disk, because it already exists.\n",
      "  skipped analyzing dataset 136, because metadata already exists.\n",
      "... processed source dataset 136: 137_UCR_Anomaly_InternalBleeding18_2300_4485_4587.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/137_UCR_Anomaly_InternalBleeding18.test.csv\n",
      "> Processing source dataset 137\n",
      "  skipped writing dataset 137 to disk, because it already exists.\n",
      "  skipped analyzing dataset 137, because metadata already exists.\n",
      "... processed source dataset 137: 138_UCR_Anomaly_InternalBleeding19_3000_4187_4197.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/138_UCR_Anomaly_InternalBleeding19.test.csv\n",
      "> Processing source dataset 138\n",
      "  skipped writing dataset 138 to disk, because it already exists.\n",
      "  skipped analyzing dataset 138, because metadata already exists.\n",
      "... processed source dataset 138: 139_UCR_Anomaly_InternalBleeding20_2700_5759_5919.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/139_UCR_Anomaly_InternalBleeding20.test.csv\n",
      "> Processing source dataset 139\n",
      "  skipped writing dataset 139 to disk, because it already exists.\n",
      "  skipped analyzing dataset 139, because metadata already exists.\n",
      "... processed source dataset 139: 140_UCR_Anomaly_InternalBleeding4_1000_4675_5033.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/140_UCR_Anomaly_InternalBleeding4.test.csv\n",
      "> Processing source dataset 140\n",
      "  skipped writing dataset 140 to disk, because it already exists.\n",
      "  skipped analyzing dataset 140, because metadata already exists.\n",
      "... processed source dataset 140: 141_UCR_Anomaly_InternalBleeding5_4000_6200_6370.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/141_UCR_Anomaly_InternalBleeding5.test.csv\n",
      "> Processing source dataset 141\n",
      "  skipped writing dataset 141 to disk, because it already exists.\n",
      "  skipped analyzing dataset 141, because metadata already exists.\n",
      "... processed source dataset 141: 142_UCR_Anomaly_InternalBleeding6_1500_3474_3629.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/142_UCR_Anomaly_InternalBleeding6.test.csv\n",
      "> Processing source dataset 142\n",
      "  skipped writing dataset 142 to disk, because it already exists.\n",
      "  skipped analyzing dataset 142, because metadata already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... processed source dataset 142: 143_UCR_Anomaly_InternalBleeding8_2500_5865_5974.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/143_UCR_Anomaly_InternalBleeding8.test.csv\n",
      "> Processing source dataset 143\n",
      "  skipped writing dataset 143 to disk, because it already exists.\n",
      "  skipped analyzing dataset 143, because metadata already exists.\n",
      "... processed source dataset 143: 144_UCR_Anomaly_InternalBleeding9_4200_6599_6681.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/144_UCR_Anomaly_InternalBleeding9.test.csv\n",
      "> Processing source dataset 144\n",
      "  skipped writing dataset 144 to disk, because it already exists.\n",
      "  skipped analyzing dataset 144, because metadata already exists.\n",
      "... processed source dataset 144: 145_UCR_Anomaly_Lab2Cmac011215EPG1_5000_17210_17260.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/145_UCR_Anomaly_Lab2Cmac011215EPG1.test.csv\n",
      "> Processing source dataset 145\n",
      "  skipped writing dataset 145 to disk, because it already exists.\n",
      "  skipped analyzing dataset 145, because metadata already exists.\n",
      "... processed source dataset 145: 146_UCR_Anomaly_Lab2Cmac011215EPG2_5000_27862_27932.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/146_UCR_Anomaly_Lab2Cmac011215EPG2.test.csv\n",
      "> Processing source dataset 146\n",
      "  skipped writing dataset 146 to disk, because it already exists.\n",
      "  skipped analyzing dataset 146, because metadata already exists.\n",
      "... processed source dataset 146: 147_UCR_Anomaly_Lab2Cmac011215EPG3_5000_16390_16420.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/147_UCR_Anomaly_Lab2Cmac011215EPG3.test.csv\n",
      "> Processing source dataset 147\n",
      "  skipped writing dataset 147 to disk, because it already exists.\n",
      "  skipped analyzing dataset 147, because metadata already exists.\n",
      "... processed source dataset 147: 148_UCR_Anomaly_Lab2Cmac011215EPG4_6000_17390_17520.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/148_UCR_Anomaly_Lab2Cmac011215EPG4.test.csv\n",
      "> Processing source dataset 148\n",
      "  skipped writing dataset 148 to disk, because it already exists.\n",
      "  skipped analyzing dataset 148, because metadata already exists.\n",
      "... processed source dataset 148: 149_UCR_Anomaly_Lab2Cmac011215EPG5_7000_17390_17520.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/149_UCR_Anomaly_Lab2Cmac011215EPG5.test.csv\n",
      "> Processing source dataset 149\n",
      "  skipped writing dataset 149 to disk, because it already exists.\n",
      "  skipped analyzing dataset 149, because metadata already exists.\n",
      "... processed source dataset 149: 150_UCR_Anomaly_Lab2Cmac011215EPG6_7000_12190_12420.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/150_UCR_Anomaly_Lab2Cmac011215EPG6.test.csv\n",
      "> Processing source dataset 150\n",
      "  skipped writing dataset 150 to disk, because it already exists.\n",
      "  skipped analyzing dataset 150, because metadata already exists.\n",
      "... processed source dataset 150: 151_UCR_Anomaly_MesoplodonDensirostris_10000_19280_19440.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/151_UCR_Anomaly_MesoplodonDensirostris.test.csv\n",
      "> Processing source dataset 151\n",
      "  skipped writing dataset 151 to disk, because it already exists.\n",
      "  skipped analyzing dataset 151, because metadata already exists.\n",
      "... processed source dataset 151: 152_UCR_Anomaly_PowerDemand1_9000_18485_18821.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/152_UCR_Anomaly_PowerDemand1.test.csv\n",
      "> Processing source dataset 152\n",
      "  skipped writing dataset 152 to disk, because it already exists.\n",
      "  skipped analyzing dataset 152, because metadata already exists.\n",
      "... processed source dataset 152: 153_UCR_Anomaly_PowerDemand2_14000_23357_23717.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/153_UCR_Anomaly_PowerDemand2.test.csv\n",
      "> Processing source dataset 153\n",
      "  skipped writing dataset 153 to disk, because it already exists.\n",
      "  skipped analyzing dataset 153, because metadata already exists.\n",
      "... processed source dataset 153: 154_UCR_Anomaly_PowerDemand3_16000_23405_23477.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/154_UCR_Anomaly_PowerDemand3.test.csv\n",
      "> Processing source dataset 154\n",
      "  skipped writing dataset 154 to disk, because it already exists.\n",
      "  skipped analyzing dataset 154, because metadata already exists.\n",
      "... processed source dataset 154: 155_UCR_Anomaly_PowerDemand4_18000_24005_24077.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/155_UCR_Anomaly_PowerDemand4.test.csv\n",
      "> Processing source dataset 155\n",
      "  skipped writing dataset 155 to disk, because it already exists.\n",
      "  skipped analyzing dataset 155, because metadata already exists.\n",
      "... processed source dataset 155: 156_UCR_Anomaly_TkeepFifthMARS_3500_5988_6085.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/156_UCR_Anomaly_TkeepFifthMARS.test.csv\n",
      "> Processing source dataset 156\n",
      "  skipped writing dataset 156 to disk, because it already exists.\n",
      "  skipped analyzing dataset 156, because metadata already exists.\n",
      "... processed source dataset 156: 157_UCR_Anomaly_TkeepFirstMARS_3500_5365_5380.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/157_UCR_Anomaly_TkeepFirstMARS.test.csv\n",
      "> Processing source dataset 157\n",
      "  skipped writing dataset 157 to disk, because it already exists.\n",
      "  skipped analyzing dataset 157, because metadata already exists.\n",
      "... processed source dataset 157: 158_UCR_Anomaly_TkeepForthMARS_3500_5988_6085.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/158_UCR_Anomaly_TkeepForthMARS.test.csv\n",
      "> Processing source dataset 158\n",
      "  skipped writing dataset 158 to disk, because it already exists.\n",
      "  skipped analyzing dataset 158, because metadata already exists.\n",
      "... processed source dataset 158: 159_UCR_Anomaly_TkeepSecondMARS_3500_9330_9340.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/159_UCR_Anomaly_TkeepSecondMARS.test.csv\n",
      "> Processing source dataset 159\n",
      "  skipped writing dataset 159 to disk, because it already exists.\n",
      "  skipped analyzing dataset 159, because metadata already exists.\n",
      "... processed source dataset 159: 160_UCR_Anomaly_TkeepThirdMARS_3500_4711_4809.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/160_UCR_Anomaly_TkeepThirdMARS.test.csv\n",
      "> Processing source dataset 160\n",
      "  skipped writing dataset 160 to disk, because it already exists.\n",
      "  skipped analyzing dataset 160, because metadata already exists.\n",
      "... processed source dataset 160: 161_UCR_Anomaly_WalkingAceleration1_1500_2764_2995.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/161_UCR_Anomaly_WalkingAceleration1.test.csv\n",
      "> Processing source dataset 161\n",
      "  skipped writing dataset 161 to disk, because it already exists.\n",
      "  skipped analyzing dataset 161, because metadata already exists.\n",
      "... processed source dataset 161: 162_UCR_Anomaly_WalkingAceleration5_2700_5920_5979.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/162_UCR_Anomaly_WalkingAceleration5.test.csv\n",
      "> Processing source dataset 162\n",
      "  skipped writing dataset 162 to disk, because it already exists.\n",
      "  skipped analyzing dataset 162, because metadata already exists.\n",
      "... processed source dataset 162: 163_UCR_Anomaly_apneaecg2_10000_20950_21100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/163_UCR_Anomaly_apneaecg2.test.csv\n",
      "> Processing source dataset 163\n",
      "  skipped writing dataset 163 to disk, because it already exists.\n",
      "  skipped analyzing dataset 163, because metadata already exists.\n",
      "... processed source dataset 163: 164_UCR_Anomaly_apneaecg3_5000_11111_11211.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/164_UCR_Anomaly_apneaecg3.test.csv\n",
      "> Processing source dataset 164\n",
      "  skipped writing dataset 164 to disk, because it already exists.\n",
      "  skipped analyzing dataset 164, because metadata already exists.\n",
      "... processed source dataset 164: 165_UCR_Anomaly_apneaecg4_6000_16000_16100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/165_UCR_Anomaly_apneaecg4.test.csv\n",
      "> Processing source dataset 165\n",
      "  skipped writing dataset 165 to disk, because it already exists.\n",
      "  skipped analyzing dataset 165, because metadata already exists.\n",
      "... processed source dataset 165: 166_UCR_Anomaly_apneaecg_10000_12240_12308.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/166_UCR_Anomaly_apneaecg.test.csv\n",
      "> Processing source dataset 166\n",
      "  skipped writing dataset 166 to disk, because it already exists.\n",
      "  skipped analyzing dataset 166, because metadata already exists.\n",
      "... processed source dataset 166: 167_UCR_Anomaly_gait1_20000_38500_38800.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/167_UCR_Anomaly_gait1.test.csv\n",
      "> Processing source dataset 167\n",
      "  skipped writing dataset 167 to disk, because it already exists.\n",
      "  skipped analyzing dataset 167, because metadata already exists.\n",
      "... processed source dataset 167: 168_UCR_Anomaly_gait2_22000_46500_46800.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/168_UCR_Anomaly_gait2.test.csv\n",
      "> Processing source dataset 168\n",
      "  skipped writing dataset 168 to disk, because it already exists.\n",
      "  skipped analyzing dataset 168, because metadata already exists.\n",
      "... processed source dataset 168: 169_UCR_Anomaly_gait3_24500_59900_60500.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/169_UCR_Anomaly_gait3.test.csv\n",
      "> Processing source dataset 169\n",
      "  skipped writing dataset 169 to disk, because it already exists.\n",
      "  skipped analyzing dataset 169, because metadata already exists.\n",
      "... processed source dataset 169: 170_UCR_Anomaly_gaitHunt1_18500_33070_33180.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/170_UCR_Anomaly_gaitHunt1.test.csv\n",
      "> Processing source dataset 170\n",
      "  skipped writing dataset 170 to disk, because it already exists.\n",
      "  skipped analyzing dataset 170, because metadata already exists.\n",
      "... processed source dataset 170: 171_UCR_Anomaly_gaitHunt2_18500_31200_31850.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/171_UCR_Anomaly_gaitHunt2.test.csv\n",
      "> Processing source dataset 171\n",
      "  skipped writing dataset 171 to disk, because it already exists.\n",
      "  skipped analyzing dataset 171, because metadata already exists.\n",
      "... processed source dataset 171: 172_UCR_Anomaly_gaitHunt3_23400_38400_39200.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/172_UCR_Anomaly_gaitHunt3.test.csv\n",
      "> Processing source dataset 172\n",
      "  skipped writing dataset 172 to disk, because it already exists.\n",
      "  skipped analyzing dataset 172, because metadata already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... processed source dataset 172: 173_UCR_Anomaly_insectEPG1_3000_7000_7030.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/173_UCR_Anomaly_insectEPG1.test.csv\n",
      "> Processing source dataset 173\n",
      "  skipped writing dataset 173 to disk, because it already exists.\n",
      "  skipped analyzing dataset 173, because metadata already exists.\n",
      "... processed source dataset 173: 174_UCR_Anomaly_insectEPG2_3700_8000_8025.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/174_UCR_Anomaly_insectEPG2.test.csv\n",
      "> Processing source dataset 174\n",
      "  skipped writing dataset 174 to disk, because it already exists.\n",
      "  skipped analyzing dataset 174, because metadata already exists.\n",
      "... processed source dataset 174: 175_UCR_Anomaly_insectEPG3_5200_7000_7050.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/175_UCR_Anomaly_insectEPG3.test.csv\n",
      "> Processing source dataset 175\n",
      "  skipped writing dataset 175 to disk, because it already exists.\n",
      "  skipped analyzing dataset 175, because metadata already exists.\n",
      "... processed source dataset 175: 176_UCR_Anomaly_insectEPG4_1300_6508_6558.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/176_UCR_Anomaly_insectEPG4.test.csv\n",
      "> Processing source dataset 176\n",
      "  skipped writing dataset 176 to disk, because it already exists.\n",
      "  skipped analyzing dataset 176, because metadata already exists.\n",
      "... processed source dataset 176: 177_UCR_Anomaly_insectEPG5_3200_8500_8501.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/177_UCR_Anomaly_insectEPG5.test.csv\n",
      "> Processing source dataset 177\n",
      "  skipped writing dataset 177 to disk, because it already exists.\n",
      "  skipped analyzing dataset 177, because metadata already exists.\n",
      "... processed source dataset 177: 178_UCR_Anomaly_ltstdbs30791AI_17555_52600_52800.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/178_UCR_Anomaly_ltstdbs30791AI.test.csv\n",
      "> Processing source dataset 178\n",
      "  skipped writing dataset 178 to disk, because it already exists.\n",
      "  skipped analyzing dataset 178, because metadata already exists.\n",
      "... processed source dataset 178: 179_UCR_Anomaly_ltstdbs30791AS_23000_52600_52800.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/179_UCR_Anomaly_ltstdbs30791AS.test.csv\n",
      "> Processing source dataset 179\n",
      "  skipped writing dataset 179 to disk, because it already exists.\n",
      "  skipped analyzing dataset 179, because metadata already exists.\n",
      "... processed source dataset 179: 180_UCR_Anomaly_ltstdbs30791ES_20000_52600_52800.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/180_UCR_Anomaly_ltstdbs30791ES.test.csv\n",
      "> Processing source dataset 180\n",
      "  skipped writing dataset 180 to disk, because it already exists.\n",
      "  skipped analyzing dataset 180, because metadata already exists.\n",
      "... processed source dataset 180: 181_UCR_Anomaly_park3m_60000_72150_72495.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/181_UCR_Anomaly_park3m.test.csv\n",
      "> Processing source dataset 181\n",
      "  skipped writing dataset 181 to disk, because it already exists.\n",
      "  skipped analyzing dataset 181, because metadata already exists.\n",
      "... processed source dataset 181: 182_UCR_Anomaly_qtdbSel1005V_4000_12400_12800.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/182_UCR_Anomaly_qtdbSel1005V.test.csv\n",
      "> Processing source dataset 182\n",
      "  skipped writing dataset 182 to disk, because it already exists.\n",
      "  skipped analyzing dataset 182, because metadata already exists.\n",
      "... processed source dataset 182: 183_UCR_Anomaly_qtdbSel100MLII_4000_13400_13800.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/183_UCR_Anomaly_qtdbSel100MLII.test.csv\n",
      "> Processing source dataset 183\n",
      "  skipped writing dataset 183 to disk, because it already exists.\n",
      "  skipped analyzing dataset 183, because metadata already exists.\n",
      "... processed source dataset 183: 184_UCR_Anomaly_resperation10_48000_130700_131880.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/184_UCR_Anomaly_resperation10.test.csv\n",
      "> Processing source dataset 184\n",
      "  skipped writing dataset 184 to disk, because it already exists.\n",
      "  skipped analyzing dataset 184, because metadata already exists.\n",
      "... processed source dataset 184: 185_UCR_Anomaly_resperation11_58000_110800_110801.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/185_UCR_Anomaly_resperation11.test.csv\n",
      "> Processing source dataset 185\n",
      "  skipped writing dataset 185 to disk, because it already exists.\n",
      "  skipped analyzing dataset 185, because metadata already exists.\n",
      "... processed source dataset 185: 186_UCR_Anomaly_resperation1_100000_110260_110412.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/186_UCR_Anomaly_resperation1.test.csv\n",
      "> Processing source dataset 186\n",
      "  skipped writing dataset 186 to disk, because it already exists.\n",
      "  skipped analyzing dataset 186, because metadata already exists.\n",
      "... processed source dataset 186: 187_UCR_Anomaly_resperation2_30000_168250_168250.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/187_UCR_Anomaly_resperation2.test.csv\n",
      "> Processing source dataset 187\n",
      "  skipped writing dataset 187 to disk, because it already exists.\n",
      "  skipped analyzing dataset 187, because metadata already exists.\n",
      "... processed source dataset 187: 188_UCR_Anomaly_resperation2_30000_168250_168251.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/188_UCR_Anomaly_resperation2.test.csv\n",
      "> Processing source dataset 188\n",
      "  skipped writing dataset 188 to disk, because it already exists.\n",
      "  skipped analyzing dataset 188, because metadata already exists.\n",
      "... processed source dataset 188: 189_UCR_Anomaly_resperation3_45000_158250_158251.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/189_UCR_Anomaly_resperation3.test.csv\n",
      "> Processing source dataset 189\n",
      "  skipped writing dataset 189 to disk, because it already exists.\n",
      "  skipped analyzing dataset 189, because metadata already exists.\n",
      "... processed source dataset 189: 190_UCR_Anomaly_resperation4_70000_128430_128431.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/190_UCR_Anomaly_resperation4.test.csv\n",
      "> Processing source dataset 190\n",
      "  skipped writing dataset 190 to disk, because it already exists.\n",
      "  skipped analyzing dataset 190, because metadata already exists.\n",
      "... processed source dataset 190: 191_UCR_Anomaly_resperation9_38000_143411_143511.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/191_UCR_Anomaly_resperation9.test.csv\n",
      "> Processing source dataset 191\n",
      "  skipped writing dataset 191 to disk, because it already exists.\n",
      "  skipped analyzing dataset 191, because metadata already exists.\n",
      "... processed source dataset 191: 192_UCR_Anomaly_s20101mML2_12000_35774_35874.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/192_UCR_Anomaly_s20101mML2.test.csv\n",
      "> Processing source dataset 192\n",
      "  skipped writing dataset 192 to disk, because it already exists.\n",
      "  skipped analyzing dataset 192, because metadata already exists.\n",
      "... processed source dataset 192: 193_UCR_Anomaly_s20101m_10000_35774_35874.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/193_UCR_Anomaly_s20101m.test.csv\n",
      "> Processing source dataset 193\n",
      "  skipped writing dataset 193 to disk, because it already exists.\n",
      "  skipped analyzing dataset 193, because metadata already exists.\n",
      "... processed source dataset 193: 194_UCR_Anomaly_sddb49_20000_67950_68200.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/194_UCR_Anomaly_sddb49.test.csv\n",
      "> Processing source dataset 194\n",
      "  skipped writing dataset 194 to disk, because it already exists.\n",
      "  skipped analyzing dataset 194, because metadata already exists.\n",
      "... processed source dataset 194: 195_UCR_Anomaly_sel840mECG1_17000_51370_51740.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/195_UCR_Anomaly_sel840mECG1.test.csv\n",
      "> Processing source dataset 195\n",
      "  skipped writing dataset 195 to disk, because it already exists.\n",
      "  skipped analyzing dataset 195, because metadata already exists.\n",
      "... processed source dataset 195: 196_UCR_Anomaly_sel840mECG2_20000_49370_49740.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/196_UCR_Anomaly_sel840mECG2.test.csv\n",
      "> Processing source dataset 196\n",
      "  skipped writing dataset 196 to disk, because it already exists.\n",
      "  skipped analyzing dataset 196, because metadata already exists.\n",
      "... processed source dataset 196: 197_UCR_Anomaly_tiltAPB1_100000_114283_114350.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/197_UCR_Anomaly_tiltAPB1.test.csv\n",
      "> Processing source dataset 197\n",
      "  skipped writing dataset 197 to disk, because it already exists.\n",
      "  skipped analyzing dataset 197, because metadata already exists.\n",
      "... processed source dataset 197: 198_UCR_Anomaly_tiltAPB2_50000_124159_124985.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/198_UCR_Anomaly_tiltAPB2.test.csv\n",
      "> Processing source dataset 198\n",
      "  skipped writing dataset 198 to disk, because it already exists.\n",
      "  skipped analyzing dataset 198, because metadata already exists.\n",
      "... processed source dataset 198: 199_UCR_Anomaly_tiltAPB3_40000_114000_114370.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/199_UCR_Anomaly_tiltAPB3.test.csv\n",
      "> Processing source dataset 199\n",
      "  skipped writing dataset 199 to disk, because it already exists.\n",
      "  skipped analyzing dataset 199, because metadata already exists.\n",
      "... processed source dataset 199: 200_UCR_Anomaly_tiltAPB4_20000_67995_67996.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/200_UCR_Anomaly_tiltAPB4.test.csv\n",
      "> Processing source dataset 200\n",
      "  skipped writing dataset 200 to disk, because it already exists.\n",
      "  skipped analyzing dataset 200, because metadata already exists.\n",
      "... processed source dataset 200: 201_UCR_Anomaly_CHARISfive_10000_17001_17016.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/201_UCR_Anomaly_CHARISfive.test.csv\n",
      "> Processing source dataset 201\n",
      "  skipped writing dataset 201 to disk, because it already exists.\n",
      "  skipped analyzing dataset 201, because metadata already exists.\n",
      "... processed source dataset 201: 202_UCR_Anomaly_CHARISfive_10411_10998_11028.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/202_UCR_Anomaly_CHARISfive.test.csv\n",
      "> Processing source dataset 202\n",
      "  skipped writing dataset 202 to disk, because it already exists.\n",
      "  skipped analyzing dataset 202, because metadata already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... processed source dataset 202: 203_UCR_Anomaly_CHARISfive_11812_10995_11028.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/203_UCR_Anomaly_CHARISfive.test.csv\n",
      "> Processing source dataset 203\n",
      "  skipped writing dataset 203 to disk, because it already exists.\n",
      "  skipped analyzing dataset 203, because metadata already exists.\n",
      "... processed source dataset 203: 204_UCR_Anomaly_CHARISfive_12412_15000_15070.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/204_UCR_Anomaly_CHARISfive.test.csv\n",
      "> Processing source dataset 204\n",
      "  skipped writing dataset 204 to disk, because it already exists.\n",
      "  skipped analyzing dataset 204, because metadata already exists.\n",
      "... processed source dataset 204: 205_UCR_Anomaly_CHARISfive_9812_28995_29085.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/205_UCR_Anomaly_CHARISfive.test.csv\n",
      "> Processing source dataset 205\n",
      "  skipped writing dataset 205 to disk, because it already exists.\n",
      "  skipped analyzing dataset 205, because metadata already exists.\n",
      "... processed source dataset 205: 206_UCR_Anomaly_CHARISten_25130_29080_29140.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/206_UCR_Anomaly_CHARISten.test.csv\n",
      "> Processing source dataset 206\n",
      "  skipped writing dataset 206 to disk, because it already exists.\n",
      "  skipped analyzing dataset 206, because metadata already exists.\n",
      "... processed source dataset 206: 207_UCR_Anomaly_CHARISten_3165_26929_26989.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/207_UCR_Anomaly_CHARISten.test.csv\n",
      "> Processing source dataset 207\n",
      "  skipped writing dataset 207 to disk, because it already exists.\n",
      "  skipped analyzing dataset 207, because metadata already exists.\n",
      "... processed source dataset 207: 208_UCR_Anomaly_CHARISten_5130_27929_27989.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/208_UCR_Anomaly_CHARISten.test.csv\n",
      "> Processing source dataset 208\n",
      "  skipped writing dataset 208 to disk, because it already exists.\n",
      "  skipped analyzing dataset 208, because metadata already exists.\n",
      "... processed source dataset 208: 209_UCR_Anomaly_Fantasia_19000_26970_27270.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/209_UCR_Anomaly_Fantasia.test.csv\n",
      "> Processing source dataset 209\n",
      "  skipped writing dataset 209 to disk, because it already exists.\n",
      "  skipped analyzing dataset 209, because metadata already exists.\n",
      "... processed source dataset 209: 210_UCR_Anomaly_Italianpowerdemand_36123_74900_74996.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/210_UCR_Anomaly_Italianpowerdemand.test.csv\n",
      "> Processing source dataset 210\n",
      "  skipped writing dataset 210 to disk, because it already exists.\n",
      "  skipped analyzing dataset 210, because metadata already exists.\n",
      "... processed source dataset 210: 211_UCR_Anomaly_Italianpowerdemand_38113_39240_39336.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/211_UCR_Anomaly_Italianpowerdemand.test.csv\n",
      "> Processing source dataset 211\n",
      "  skipped writing dataset 211 to disk, because it already exists.\n",
      "  skipped analyzing dataset 211, because metadata already exists.\n",
      "... processed source dataset 211: 212_UCR_Anomaly_Italianpowerdemand_8913_29480_29504.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/212_UCR_Anomaly_Italianpowerdemand.test.csv\n",
      "> Processing source dataset 212\n",
      "  skipped writing dataset 212 to disk, because it already exists.\n",
      "  skipped analyzing dataset 212, because metadata already exists.\n",
      "... processed source dataset 212: 213_UCR_Anomaly_STAFFIIIDatabase_33211_126920_127370.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/213_UCR_Anomaly_STAFFIIIDatabase.test.csv\n",
      "> Processing source dataset 213\n",
      "  skipped writing dataset 213 to disk, because it already exists.\n",
      "  skipped analyzing dataset 213, because metadata already exists.\n",
      "... processed source dataset 213: 214_UCR_Anomaly_STAFFIIIDatabase_34211_125720_126370.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/214_UCR_Anomaly_STAFFIIIDatabase.test.csv\n",
      "> Processing source dataset 214\n",
      "  skipped writing dataset 214 to disk, because it already exists.\n",
      "  skipped analyzing dataset 214, because metadata already exists.\n",
      "... processed source dataset 214: 215_UCR_Anomaly_STAFFIIIDatabase_36276_106720_107370.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/215_UCR_Anomaly_STAFFIIIDatabase.test.csv\n",
      "> Processing source dataset 215\n",
      "  skipped writing dataset 215 to disk, because it already exists.\n",
      "  skipped analyzing dataset 215, because metadata already exists.\n",
      "... processed source dataset 215: 216_UCR_Anomaly_STAFFIIIDatabase_37216_160720_161370.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/216_UCR_Anomaly_STAFFIIIDatabase.test.csv\n",
      "> Processing source dataset 216\n",
      "  skipped writing dataset 216 to disk, because it already exists.\n",
      "  skipped analyzing dataset 216, because metadata already exists.\n",
      "... processed source dataset 216: 217_UCR_Anomaly_STAFFIIIDatabase_38211_150720_151370.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/217_UCR_Anomaly_STAFFIIIDatabase.test.csv\n",
      "> Processing source dataset 217\n",
      "  skipped writing dataset 217 to disk, because it already exists.\n",
      "  skipped analyzing dataset 217, because metadata already exists.\n",
      "... processed source dataset 217: 218_UCR_Anomaly_STAFFIIIDatabase_41117_210720_211370.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/218_UCR_Anomaly_STAFFIIIDatabase.test.csv\n",
      "> Processing source dataset 218\n",
      "  skipped writing dataset 218 to disk, because it already exists.\n",
      "  skipped analyzing dataset 218, because metadata already exists.\n",
      "... processed source dataset 218: 219_UCR_Anomaly_STAFFIIIDatabase_41612_64632_64852.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/219_UCR_Anomaly_STAFFIIIDatabase.test.csv\n",
      "> Processing source dataset 219\n",
      "  skipped writing dataset 219 to disk, because it already exists.\n",
      "  skipped analyzing dataset 219, because metadata already exists.\n",
      "... processed source dataset 219: 220_UCR_Anomaly_STAFFIIIDatabase_43217_250720_251370.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/220_UCR_Anomaly_STAFFIIIDatabase.test.csv\n",
      "> Processing source dataset 220\n",
      "  skipped writing dataset 220 to disk, because it already exists.\n",
      "  skipped analyzing dataset 220, because metadata already exists.\n",
      "... processed source dataset 220: 221_UCR_Anomaly_STAFFIIIDatabase_45616_163632_164852.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/221_UCR_Anomaly_STAFFIIIDatabase.test.csv\n",
      "> Processing source dataset 221\n",
      "  skipped writing dataset 221 to disk, because it already exists.\n",
      "  skipped analyzing dataset 221, because metadata already exists.\n",
      "... processed source dataset 221: 222_UCR_Anomaly_mit14046longtermecg_56123_91200_91700.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/222_UCR_Anomaly_mit14046longtermecg.test.csv\n",
      "> Processing source dataset 222\n",
      "  skipped writing dataset 222 to disk, because it already exists.\n",
      "  skipped analyzing dataset 222, because metadata already exists.\n",
      "... processed source dataset 222: 223_UCR_Anomaly_mit14046longtermecg_74123_131200_131700.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/223_UCR_Anomaly_mit14046longtermecg.test.csv\n",
      "> Processing source dataset 223\n",
      "  skipped writing dataset 223 to disk, because it already exists.\n",
      "  skipped analyzing dataset 223, because metadata already exists.\n",
      "... processed source dataset 223: 224_UCR_Anomaly_mit14046longtermecg_76123_191200_191700.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/224_UCR_Anomaly_mit14046longtermecg.test.csv\n",
      "> Processing source dataset 224\n",
      "  skipped writing dataset 224 to disk, because it already exists.\n",
      "  skipped analyzing dataset 224, because metadata already exists.\n",
      "... processed source dataset 224: 225_UCR_Anomaly_mit14046longtermecg_81214_143000_143300.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/225_UCR_Anomaly_mit14046longtermecg.test.csv\n",
      "> Processing source dataset 225\n",
      "  skipped writing dataset 225 to disk, because it already exists.\n",
      "  skipped analyzing dataset 225, because metadata already exists.\n",
      "... processed source dataset 225: 226_UCR_Anomaly_mit14046longtermecg_96123_123000_123300.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/226_UCR_Anomaly_mit14046longtermecg.test.csv\n",
      "> Processing source dataset 226\n",
      "  skipped writing dataset 226 to disk, because it already exists.\n",
      "  skipped analyzing dataset 226, because metadata already exists.\n",
      "... processed source dataset 226: 227_UCR_Anomaly_mit14134longtermecg_11231_29000_29100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/227_UCR_Anomaly_mit14134longtermecg.test.csv\n",
      "> Processing source dataset 227\n",
      "  skipped writing dataset 227 to disk, because it already exists.\n",
      "  skipped analyzing dataset 227, because metadata already exists.\n",
      "... processed source dataset 227: 228_UCR_Anomaly_mit14134longtermecg_11361_47830_47850.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/228_UCR_Anomaly_mit14134longtermecg.test.csv\n",
      "> Processing source dataset 228\n",
      "  skipped writing dataset 228 to disk, because it already exists.\n",
      "  skipped analyzing dataset 228, because metadata already exists.\n",
      "... processed source dataset 228: 229_UCR_Anomaly_mit14134longtermecg_16363_57960_57970.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/229_UCR_Anomaly_mit14134longtermecg.test.csv\n",
      "> Processing source dataset 229\n",
      "  skipped writing dataset 229 to disk, because it already exists.\n",
      "  skipped analyzing dataset 229, because metadata already exists.\n",
      "... processed source dataset 229: 230_UCR_Anomaly_mit14134longtermecg_19363_19510_19610.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/230_UCR_Anomaly_mit14134longtermecg.test.csv\n",
      "> Processing source dataset 230\n",
      "  skipped writing dataset 230 to disk, because it already exists.\n",
      "  skipped analyzing dataset 230, because metadata already exists.\n",
      "... processed source dataset 230: 231_UCR_Anomaly_mit14134longtermecg_8763_47530_47790.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/231_UCR_Anomaly_mit14134longtermecg.test.csv\n",
      "> Processing source dataset 231\n",
      "  skipped writing dataset 231 to disk, because it already exists.\n",
      "  skipped analyzing dataset 231, because metadata already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... processed source dataset 231: 232_UCR_Anomaly_mit14134longtermecg_8763_57530_57790.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/232_UCR_Anomaly_mit14134longtermecg.test.csv\n",
      "> Processing source dataset 232\n",
      "  skipped writing dataset 232 to disk, because it already exists.\n",
      "  skipped analyzing dataset 232, because metadata already exists.\n",
      "... processed source dataset 232: 233_UCR_Anomaly_mit14157longtermecg_18913_24500_24501.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/233_UCR_Anomaly_mit14157longtermecg.test.csv\n",
      "> Processing source dataset 233\n",
      "  skipped writing dataset 233 to disk, because it already exists.\n",
      "  skipped analyzing dataset 233, because metadata already exists.\n",
      "... processed source dataset 233: 234_UCR_Anomaly_mit14157longtermecg_18913_24600_24601.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/234_UCR_Anomaly_mit14157longtermecg.test.csv\n",
      "> Processing source dataset 234\n",
      "  skipped writing dataset 234 to disk, because it already exists.\n",
      "  skipped analyzing dataset 234, because metadata already exists.\n",
      "... processed source dataset 234: 235_UCR_Anomaly_mit14157longtermecg_18913_75450_75451.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/235_UCR_Anomaly_mit14157longtermecg.test.csv\n",
      "> Processing source dataset 235\n",
      "  skipped writing dataset 235 to disk, because it already exists.\n",
      "  skipped analyzing dataset 235, because metadata already exists.\n",
      "... processed source dataset 235: 236_UCR_Anomaly_mit14157longtermecg_19313_46350_46390.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/236_UCR_Anomaly_mit14157longtermecg.test.csv\n",
      "> Processing source dataset 236\n",
      "  skipped writing dataset 236 to disk, because it already exists.\n",
      "  skipped analyzing dataset 236, because metadata already exists.\n",
      "... processed source dataset 236: 237_UCR_Anomaly_mit14157longtermecg_19313_89560_90370.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/237_UCR_Anomaly_mit14157longtermecg.test.csv\n",
      "> Processing source dataset 237\n",
      "  skipped writing dataset 237 to disk, because it already exists.\n",
      "  skipped analyzing dataset 237, because metadata already exists.\n",
      "... processed source dataset 237: 238_UCR_Anomaly_mit14157longtermecg_21311_72600_72780.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/238_UCR_Anomaly_mit14157longtermecg.test.csv\n",
      "> Processing source dataset 238\n",
      "  skipped writing dataset 238 to disk, because it already exists.\n",
      "  skipped analyzing dataset 238, because metadata already exists.\n",
      "... processed source dataset 238: 239_UCR_Anomaly_taichidbS0715Master_190037_593450_593514.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/239_UCR_Anomaly_taichidbS0715Master.test.csv\n",
      "> Processing source dataset 239\n",
      "  written dataset 239\n",
      "  analyzed test dataset 239\n",
      "  analyzed training dataset 239\n",
      "... processed source dataset 239: 240_UCR_Anomaly_taichidbS0715Master_240030_884100_884200.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/240_UCR_Anomaly_taichidbS0715Master.test.csv\n",
      "> Processing source dataset 240\n",
      "  written dataset 240\n",
      "  analyzed test dataset 240\n",
      "  analyzed training dataset 240\n",
      "... processed source dataset 240: 241_UCR_Anomaly_taichidbS0715Master_250000_837400_839100.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/241_UCR_Anomaly_taichidbS0715Master.test.csv\n",
      "> Processing source dataset 241\n",
      "  written dataset 241\n",
      "  analyzed test dataset 241\n",
      "  analyzed training dataset 241\n",
      "... processed source dataset 241: 242_UCR_Anomaly_tilt12744mtable_100000_104630_104890.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/242_UCR_Anomaly_tilt12744mtable.test.csv\n",
      "> Processing source dataset 242\n",
      "  written dataset 242\n",
      "  analyzed test dataset 242\n",
      "  analyzed training dataset 242\n",
      "... processed source dataset 242: 243_UCR_Anomaly_tilt12744mtable_100000_203355_203400.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/243_UCR_Anomaly_tilt12744mtable.test.csv\n",
      "> Processing source dataset 243\n",
      "  written dataset 243\n",
      "  analyzed test dataset 243\n",
      "  analyzed training dataset 243\n",
      "... processed source dataset 243: 244_UCR_Anomaly_tilt12754table_100013_104630_104890.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/244_UCR_Anomaly_tilt12754table.test.csv\n",
      "> Processing source dataset 244\n",
      "  written dataset 244\n",
      "  analyzed test dataset 244\n",
      "  analyzed training dataset 244\n",
      "... processed source dataset 244: 245_UCR_Anomaly_tilt12754table_100211_270800_271070.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/245_UCR_Anomaly_tilt12754table.test.csv\n",
      "> Processing source dataset 245\n",
      "  written dataset 245\n",
      "  analyzed test dataset 245\n",
      "  analyzed training dataset 245\n",
      "... processed source dataset 245: 246_UCR_Anomaly_tilt12755mtable_100211_270800_271070.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/246_UCR_Anomaly_tilt12755mtable.test.csv\n",
      "> Processing source dataset 246\n",
      "  written dataset 246\n",
      "  analyzed test dataset 246\n",
      "  analyzed training dataset 246\n",
      "... processed source dataset 246: 247_UCR_Anomaly_tilt12755mtable_50211_121900_121980.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/247_UCR_Anomaly_tilt12755mtable.test.csv\n",
      "> Processing source dataset 247\n",
      "  written dataset 247\n",
      "  analyzed test dataset 247\n",
      "  analyzed training dataset 247\n",
      "... processed source dataset 247: 248_UCR_Anomaly_weallwalk_2000_4702_4707.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/248_UCR_Anomaly_weallwalk.test.csv\n",
      "> Processing source dataset 248\n",
      "  written dataset 248\n",
      "  analyzed test dataset 248\n",
      "  analyzed training dataset 248\n",
      "... processed source dataset 248: 249_UCR_Anomaly_weallwalk_2753_8285_8315.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/249_UCR_Anomaly_weallwalk.test.csv\n",
      "> Processing source dataset 249\n",
      "  written dataset 249\n",
      "  analyzed test dataset 249\n",
      "  analyzed training dataset 249\n",
      "... processed source dataset 249: 250_UCR_Anomaly_weallwalk_2951_7290_7296.txt -> /home/sebastian/Documents/Projects/akita/data/benchmark-data/data-processed/univariate/KDD-TSAD/250_UCR_Anomaly_weallwalk.test.csv\n"
     ]
    }
   ],
   "source": [
    "def process_dataset(dm: Datasets, idx: int, f: Path) -> None:\n",
    "    print(f\"> Processing source dataset {idx}\")\n",
    "    name_parts = f.stem.split(\"_\")\n",
    "    dataset_name = \"_\".join(name_parts[:-3])\n",
    "    split_at = int(name_parts[-3])\n",
    "    anomaly = tuple(int(idx) for idx in name_parts[-2:])\n",
    "    test_filename = f\"{dataset_name}.test.csv\"\n",
    "    train_filename = f\"{dataset_name}.train.csv\"\n",
    "    test_path = dataset_subfolder / test_filename\n",
    "    train_path = dataset_subfolder / train_filename\n",
    "    target_test_filepath = target_subfolder / test_filename\n",
    "    target_train_filepath = target_subfolder / train_filename\n",
    "    target_meta_filepath = target_test_filepath.parent / f\"{dataset_name}.{Datasets.METADATA_FILENAME_PREFIX}\"\n",
    "\n",
    "    # Prepare datasets\n",
    "    if not target_test_filepath.exists() or not target_train_filepath.exists() or not target_meta_filepath.exists():\n",
    "        data = np.genfromtxt(f)\n",
    "        df_test = pd.DataFrame(data, columns=[\"value\"])\n",
    "        df_test.insert(0, \"timestamp\", df_test.index.values)\n",
    "        df_test[\"is_anomaly\"] = 0\n",
    "        df_test.loc[range(anomaly[0], anomaly[1]), \"is_anomaly\"] = 1\n",
    "        df_test.to_csv(target_test_filepath, index=False)\n",
    "\n",
    "        df_train = df_test[:split_at].copy()\n",
    "        df_train.to_csv(target_train_filepath, index=False)\n",
    "        print(f\"  written dataset {idx}\")\n",
    "    else:\n",
    "        df_test = df_train = None\n",
    "        print(f\"  skipped writing dataset {idx} to disk, because it already exists.\")\n",
    "    \n",
    "    ignore_stationarity = idx > 237\n",
    "\n",
    "    # Prepare metadata\n",
    "    def analyze(df_test, df_train):\n",
    "        da = DatasetAnalyzer((dataset_collection_name, dataset_name), is_train=False, df=df_test, ignore_stationarity=ignore_stationarity)\n",
    "        da.save_to_json(target_meta_filepath, overwrite=True)\n",
    "        meta = da.metadata\n",
    "        print(f\"  analyzed test dataset {idx}\")\n",
    "\n",
    "        DatasetAnalyzer((dataset_collection_name, dataset_name), is_train=True, df=df_train, ignore_stationarity=ignore_stationarity)\\\n",
    "            .save_to_json(target_meta_filepath, overwrite=False)\n",
    "        print(f\"  analyzed training dataset {idx}\")\n",
    "        return meta\n",
    "        \n",
    "    if target_meta_filepath.exists():\n",
    "        try:\n",
    "            meta = DatasetAnalyzer.load_from_json(target_meta_filepath, train=False)\n",
    "        except ValueError:\n",
    "            if df_test is None:\n",
    "                df_test = pd.read_csv(target_test_filepath)\n",
    "            if df_train is None:\n",
    "                df_train = pd.read_csv(target_train_filepath)\n",
    "            meta = analyze(df_test, df_train)\n",
    "        else:\n",
    "\n",
    "            # check if train metadata is also present\n",
    "            try:\n",
    "                DatasetAnalyzer.load_from_json(target_meta_filepath, train=True)\n",
    "                print(f\"  skipped analyzing dataset {idx}, because metadata already exists.\")\n",
    "            except ValueError:\n",
    "                if df_train is None:\n",
    "                    df_train = pd.read_csv(target_train_filepath)\n",
    "                DatasetAnalyzer((dataset_collection_name, dataset_name), is_train=True, df=df_train, ignore_stationarity=ignore_stationarity)\\\n",
    "                    .save_to_json(target_meta_filepath, overwrite=False)\n",
    "                print(f\"  analyzed training dataset {idx}\")\n",
    "    else:\n",
    "        meta = analyze(df_test, df_train)\n",
    "\n",
    "    dm.add_dataset(DatasetRecord(\n",
    "          collection_name=dataset_collection_name,\n",
    "          dataset_name=dataset_name,\n",
    "          train_path=train_path,\n",
    "          test_path=test_path,\n",
    "          dataset_type=dataset_type,\n",
    "          datetime_index=datetime_index,\n",
    "          split_at=split_at,\n",
    "          train_type=train_type,\n",
    "          train_is_normal=train_is_normal,\n",
    "          input_type=input_type,\n",
    "          length=meta.length,\n",
    "          dimensions=meta.dimensions,\n",
    "          contamination=meta.contamination,\n",
    "          num_anomalies=meta.num_anomalies,\n",
    "          min_anomaly_length=meta.anomaly_length.min,\n",
    "          median_anomaly_length=meta.anomaly_length.median,\n",
    "          max_anomaly_length=meta.anomaly_length.max,\n",
    "          mean=meta.mean,\n",
    "          stddev=meta.stddev,\n",
    "          trend=meta.trend,\n",
    "          stationarity=meta.get_stationarity_name(),\n",
    "          period_size=np.nan\n",
    "    ))\n",
    "    print(f\"... processed source dataset {idx}: {f.name} -> {target_test_filepath}\")\n",
    "\n",
    "for i, file in enumerate(find_datasets(source_folder)):\n",
    "    process_dataset(dm, i, file)\n",
    "dm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>train_path</th>\n",
       "      <th>test_path</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>datetime_index</th>\n",
       "      <th>split_at</th>\n",
       "      <th>train_type</th>\n",
       "      <th>train_is_normal</th>\n",
       "      <th>input_type</th>\n",
       "      <th>length</th>\n",
       "      <th>dimensions</th>\n",
       "      <th>contamination</th>\n",
       "      <th>num_anomalies</th>\n",
       "      <th>min_anomaly_length</th>\n",
       "      <th>median_anomaly_length</th>\n",
       "      <th>max_anomaly_length</th>\n",
       "      <th>mean</th>\n",
       "      <th>stddev</th>\n",
       "      <th>trend</th>\n",
       "      <th>stationarity</th>\n",
       "      <th>period_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collection_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">KDD-TSAD</th>\n",
       "      <th>001_UCR_Anomaly_DISTORTED1sddb40</th>\n",
       "      <td>univariate/KDD-TSAD/001_UCR_Anomaly_DISTORTED1...</td>\n",
       "      <td>univariate/KDD-TSAD/001_UCR_Anomaly_DISTORTED1...</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>False</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>semi-supervised</td>\n",
       "      <td>True</td>\n",
       "      <td>univariate</td>\n",
       "      <td>79795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>620</td>\n",
       "      <td>-27.144590</td>\n",
       "      <td>175.478213</td>\n",
       "      <td>no trend</td>\n",
       "      <td>difference_stationary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002_UCR_Anomaly_DISTORTED2sddb40</th>\n",
       "      <td>univariate/KDD-TSAD/002_UCR_Anomaly_DISTORTED2...</td>\n",
       "      <td>univariate/KDD-TSAD/002_UCR_Anomaly_DISTORTED2...</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>False</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>semi-supervised</td>\n",
       "      <td>True</td>\n",
       "      <td>univariate</td>\n",
       "      <td>80001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>-25.141412</td>\n",
       "      <td>173.018208</td>\n",
       "      <td>no trend</td>\n",
       "      <td>difference_stationary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003_UCR_Anomaly_DISTORTED3sddb40</th>\n",
       "      <td>univariate/KDD-TSAD/003_UCR_Anomaly_DISTORTED3...</td>\n",
       "      <td>univariate/KDD-TSAD/003_UCR_Anomaly_DISTORTED3...</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>False</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>semi-supervised</td>\n",
       "      <td>True</td>\n",
       "      <td>univariate</td>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>-24.828451</td>\n",
       "      <td>172.602470</td>\n",
       "      <td>no trend</td>\n",
       "      <td>difference_stationary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004_UCR_Anomaly</th>\n",
       "      <td>univariate/KDD-TSAD/004_UCR_Anomaly.train.csv</td>\n",
       "      <td>univariate/KDD-TSAD/004_UCR_Anomaly.test.csv</td>\n",
       "      <td>real</td>\n",
       "      <td>False</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>semi-supervised</td>\n",
       "      <td>True</td>\n",
       "      <td>univariate</td>\n",
       "      <td>11000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>1130.949099</td>\n",
       "      <td>9315.219071</td>\n",
       "      <td>no trend</td>\n",
       "      <td>difference_stationary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004_UCR_Anomaly_DISTORTEDBIDMC1</th>\n",
       "      <td>univariate/KDD-TSAD/004_UCR_Anomaly_DISTORTEDB...</td>\n",
       "      <td>univariate/KDD-TSAD/004_UCR_Anomaly_DISTORTEDB...</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>False</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>semi-supervised</td>\n",
       "      <td>True</td>\n",
       "      <td>univariate</td>\n",
       "      <td>11000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>1130.949099</td>\n",
       "      <td>9315.219071</td>\n",
       "      <td>no trend</td>\n",
       "      <td>difference_stationary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246_UCR_Anomaly_tilt12755mtable</th>\n",
       "      <td>univariate/KDD-TSAD/246_UCR_Anomaly_tilt12755m...</td>\n",
       "      <td>univariate/KDD-TSAD/246_UCR_Anomaly_tilt12755m...</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>False</td>\n",
       "      <td>100211.0</td>\n",
       "      <td>semi-supervised</td>\n",
       "      <td>True</td>\n",
       "      <td>univariate</td>\n",
       "      <td>299867</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>270</td>\n",
       "      <td>270</td>\n",
       "      <td>5041.727730</td>\n",
       "      <td>889.323740</td>\n",
       "      <td>no trend</td>\n",
       "      <td>not_stationary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247_UCR_Anomaly_tilt12755mtable</th>\n",
       "      <td>univariate/KDD-TSAD/247_UCR_Anomaly_tilt12755m...</td>\n",
       "      <td>univariate/KDD-TSAD/247_UCR_Anomaly_tilt12755m...</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>False</td>\n",
       "      <td>50211.0</td>\n",
       "      <td>semi-supervised</td>\n",
       "      <td>True</td>\n",
       "      <td>univariate</td>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>4978.535763</td>\n",
       "      <td>876.777608</td>\n",
       "      <td>no trend</td>\n",
       "      <td>not_stationary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248_UCR_Anomaly_weallwalk</th>\n",
       "      <td>univariate/KDD-TSAD/248_UCR_Anomaly_weallwalk....</td>\n",
       "      <td>univariate/KDD-TSAD/248_UCR_Anomaly_weallwalk....</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>False</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>semi-supervised</td>\n",
       "      <td>True</td>\n",
       "      <td>univariate</td>\n",
       "      <td>8432</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.185222</td>\n",
       "      <td>0.398741</td>\n",
       "      <td>no trend</td>\n",
       "      <td>not_stationary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249_UCR_Anomaly_weallwalk</th>\n",
       "      <td>univariate/KDD-TSAD/249_UCR_Anomaly_weallwalk....</td>\n",
       "      <td>univariate/KDD-TSAD/249_UCR_Anomaly_weallwalk....</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>False</td>\n",
       "      <td>2753.0</td>\n",
       "      <td>semi-supervised</td>\n",
       "      <td>True</td>\n",
       "      <td>univariate</td>\n",
       "      <td>10524</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>-1.185866</td>\n",
       "      <td>0.392685</td>\n",
       "      <td>no trend</td>\n",
       "      <td>not_stationary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250_UCR_Anomaly_weallwalk</th>\n",
       "      <td>univariate/KDD-TSAD/250_UCR_Anomaly_weallwalk....</td>\n",
       "      <td>univariate/KDD-TSAD/250_UCR_Anomaly_weallwalk....</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>False</td>\n",
       "      <td>2951.0</td>\n",
       "      <td>semi-supervised</td>\n",
       "      <td>True</td>\n",
       "      <td>univariate</td>\n",
       "      <td>10468</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.185361</td>\n",
       "      <td>0.394378</td>\n",
       "      <td>no trend</td>\n",
       "      <td>not_stationary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows  20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         train_path  \\\n",
       "collection_name dataset_name                                                                          \n",
       "KDD-TSAD        001_UCR_Anomaly_DISTORTED1sddb40  univariate/KDD-TSAD/001_UCR_Anomaly_DISTORTED1...   \n",
       "                002_UCR_Anomaly_DISTORTED2sddb40  univariate/KDD-TSAD/002_UCR_Anomaly_DISTORTED2...   \n",
       "                003_UCR_Anomaly_DISTORTED3sddb40  univariate/KDD-TSAD/003_UCR_Anomaly_DISTORTED3...   \n",
       "                004_UCR_Anomaly                       univariate/KDD-TSAD/004_UCR_Anomaly.train.csv   \n",
       "                004_UCR_Anomaly_DISTORTEDBIDMC1   univariate/KDD-TSAD/004_UCR_Anomaly_DISTORTEDB...   \n",
       "...                                                                                             ...   \n",
       "                246_UCR_Anomaly_tilt12755mtable   univariate/KDD-TSAD/246_UCR_Anomaly_tilt12755m...   \n",
       "                247_UCR_Anomaly_tilt12755mtable   univariate/KDD-TSAD/247_UCR_Anomaly_tilt12755m...   \n",
       "                248_UCR_Anomaly_weallwalk         univariate/KDD-TSAD/248_UCR_Anomaly_weallwalk....   \n",
       "                249_UCR_Anomaly_weallwalk         univariate/KDD-TSAD/249_UCR_Anomaly_weallwalk....   \n",
       "                250_UCR_Anomaly_weallwalk         univariate/KDD-TSAD/250_UCR_Anomaly_weallwalk....   \n",
       "\n",
       "                                                                                          test_path  \\\n",
       "collection_name dataset_name                                                                          \n",
       "KDD-TSAD        001_UCR_Anomaly_DISTORTED1sddb40  univariate/KDD-TSAD/001_UCR_Anomaly_DISTORTED1...   \n",
       "                002_UCR_Anomaly_DISTORTED2sddb40  univariate/KDD-TSAD/002_UCR_Anomaly_DISTORTED2...   \n",
       "                003_UCR_Anomaly_DISTORTED3sddb40  univariate/KDD-TSAD/003_UCR_Anomaly_DISTORTED3...   \n",
       "                004_UCR_Anomaly                        univariate/KDD-TSAD/004_UCR_Anomaly.test.csv   \n",
       "                004_UCR_Anomaly_DISTORTEDBIDMC1   univariate/KDD-TSAD/004_UCR_Anomaly_DISTORTEDB...   \n",
       "...                                                                                             ...   \n",
       "                246_UCR_Anomaly_tilt12755mtable   univariate/KDD-TSAD/246_UCR_Anomaly_tilt12755m...   \n",
       "                247_UCR_Anomaly_tilt12755mtable   univariate/KDD-TSAD/247_UCR_Anomaly_tilt12755m...   \n",
       "                248_UCR_Anomaly_weallwalk         univariate/KDD-TSAD/248_UCR_Anomaly_weallwalk....   \n",
       "                249_UCR_Anomaly_weallwalk         univariate/KDD-TSAD/249_UCR_Anomaly_weallwalk....   \n",
       "                250_UCR_Anomaly_weallwalk         univariate/KDD-TSAD/250_UCR_Anomaly_weallwalk....   \n",
       "\n",
       "                                                 dataset_type  datetime_index  \\\n",
       "collection_name dataset_name                                                    \n",
       "KDD-TSAD        001_UCR_Anomaly_DISTORTED1sddb40    synthetic           False   \n",
       "                002_UCR_Anomaly_DISTORTED2sddb40    synthetic           False   \n",
       "                003_UCR_Anomaly_DISTORTED3sddb40    synthetic           False   \n",
       "                004_UCR_Anomaly                          real           False   \n",
       "                004_UCR_Anomaly_DISTORTEDBIDMC1     synthetic           False   \n",
       "...                                                       ...             ...   \n",
       "                246_UCR_Anomaly_tilt12755mtable     synthetic           False   \n",
       "                247_UCR_Anomaly_tilt12755mtable     synthetic           False   \n",
       "                248_UCR_Anomaly_weallwalk           synthetic           False   \n",
       "                249_UCR_Anomaly_weallwalk           synthetic           False   \n",
       "                250_UCR_Anomaly_weallwalk           synthetic           False   \n",
       "\n",
       "                                                  split_at       train_type  \\\n",
       "collection_name dataset_name                                                  \n",
       "KDD-TSAD        001_UCR_Anomaly_DISTORTED1sddb40   35000.0  semi-supervised   \n",
       "                002_UCR_Anomaly_DISTORTED2sddb40   35000.0  semi-supervised   \n",
       "                003_UCR_Anomaly_DISTORTED3sddb40   35000.0  semi-supervised   \n",
       "                004_UCR_Anomaly                     2500.0  semi-supervised   \n",
       "                004_UCR_Anomaly_DISTORTEDBIDMC1     2500.0  semi-supervised   \n",
       "...                                                    ...              ...   \n",
       "                246_UCR_Anomaly_tilt12755mtable   100211.0  semi-supervised   \n",
       "                247_UCR_Anomaly_tilt12755mtable    50211.0  semi-supervised   \n",
       "                248_UCR_Anomaly_weallwalk           2000.0  semi-supervised   \n",
       "                249_UCR_Anomaly_weallwalk           2753.0  semi-supervised   \n",
       "                250_UCR_Anomaly_weallwalk           2951.0  semi-supervised   \n",
       "\n",
       "                                                  train_is_normal  input_type  \\\n",
       "collection_name dataset_name                                                    \n",
       "KDD-TSAD        001_UCR_Anomaly_DISTORTED1sddb40             True  univariate   \n",
       "                002_UCR_Anomaly_DISTORTED2sddb40             True  univariate   \n",
       "                003_UCR_Anomaly_DISTORTED3sddb40             True  univariate   \n",
       "                004_UCR_Anomaly                              True  univariate   \n",
       "                004_UCR_Anomaly_DISTORTEDBIDMC1              True  univariate   \n",
       "...                                                           ...         ...   \n",
       "                246_UCR_Anomaly_tilt12755mtable              True  univariate   \n",
       "                247_UCR_Anomaly_tilt12755mtable              True  univariate   \n",
       "                248_UCR_Anomaly_weallwalk                    True  univariate   \n",
       "                249_UCR_Anomaly_weallwalk                    True  univariate   \n",
       "                250_UCR_Anomaly_weallwalk                    True  univariate   \n",
       "\n",
       "                                                  length  dimensions  \\\n",
       "collection_name dataset_name                                           \n",
       "KDD-TSAD        001_UCR_Anomaly_DISTORTED1sddb40   79795           1   \n",
       "                002_UCR_Anomaly_DISTORTED2sddb40   80001           1   \n",
       "                003_UCR_Anomaly_DISTORTED3sddb40   80000           1   \n",
       "                004_UCR_Anomaly                    11000           1   \n",
       "                004_UCR_Anomaly_DISTORTEDBIDMC1    11000           1   \n",
       "...                                                  ...         ...   \n",
       "                246_UCR_Anomaly_tilt12755mtable   299867           1   \n",
       "                247_UCR_Anomaly_tilt12755mtable   200000           1   \n",
       "                248_UCR_Anomaly_weallwalk           8432           1   \n",
       "                249_UCR_Anomaly_weallwalk          10524           1   \n",
       "                250_UCR_Anomaly_weallwalk          10468           1   \n",
       "\n",
       "                                                  contamination  \\\n",
       "collection_name dataset_name                                      \n",
       "KDD-TSAD        001_UCR_Anomaly_DISTORTED1sddb40       0.007770   \n",
       "                002_UCR_Anomaly_DISTORTED2sddb40       0.003750   \n",
       "                003_UCR_Anomaly_DISTORTED3sddb40       0.003750   \n",
       "                004_UCR_Anomaly                        0.018182   \n",
       "                004_UCR_Anomaly_DISTORTEDBIDMC1        0.018182   \n",
       "...                                                         ...   \n",
       "                246_UCR_Anomaly_tilt12755mtable        0.000900   \n",
       "                247_UCR_Anomaly_tilt12755mtable        0.000400   \n",
       "                248_UCR_Anomaly_weallwalk              0.000593   \n",
       "                249_UCR_Anomaly_weallwalk              0.002851   \n",
       "                250_UCR_Anomaly_weallwalk              0.000573   \n",
       "\n",
       "                                                  num_anomalies  \\\n",
       "collection_name dataset_name                                      \n",
       "KDD-TSAD        001_UCR_Anomaly_DISTORTED1sddb40              1   \n",
       "                002_UCR_Anomaly_DISTORTED2sddb40              1   \n",
       "                003_UCR_Anomaly_DISTORTED3sddb40              1   \n",
       "                004_UCR_Anomaly                               1   \n",
       "                004_UCR_Anomaly_DISTORTEDBIDMC1               1   \n",
       "...                                                         ...   \n",
       "                246_UCR_Anomaly_tilt12755mtable               1   \n",
       "                247_UCR_Anomaly_tilt12755mtable               1   \n",
       "                248_UCR_Anomaly_weallwalk                     1   \n",
       "                249_UCR_Anomaly_weallwalk                     1   \n",
       "                250_UCR_Anomaly_weallwalk                     1   \n",
       "\n",
       "                                                  min_anomaly_length  \\\n",
       "collection_name dataset_name                                           \n",
       "KDD-TSAD        001_UCR_Anomaly_DISTORTED1sddb40                 620   \n",
       "                002_UCR_Anomaly_DISTORTED2sddb40                 300   \n",
       "                003_UCR_Anomaly_DISTORTED3sddb40                 300   \n",
       "                004_UCR_Anomaly                                  200   \n",
       "                004_UCR_Anomaly_DISTORTEDBIDMC1                  200   \n",
       "...                                                              ...   \n",
       "                246_UCR_Anomaly_tilt12755mtable                  270   \n",
       "                247_UCR_Anomaly_tilt12755mtable                   80   \n",
       "                248_UCR_Anomaly_weallwalk                          5   \n",
       "                249_UCR_Anomaly_weallwalk                         30   \n",
       "                250_UCR_Anomaly_weallwalk                          6   \n",
       "\n",
       "                                                  median_anomaly_length  \\\n",
       "collection_name dataset_name                                              \n",
       "KDD-TSAD        001_UCR_Anomaly_DISTORTED1sddb40                    620   \n",
       "                002_UCR_Anomaly_DISTORTED2sddb40                    300   \n",
       "                003_UCR_Anomaly_DISTORTED3sddb40                    300   \n",
       "                004_UCR_Anomaly                                     200   \n",
       "                004_UCR_Anomaly_DISTORTEDBIDMC1                     200   \n",
       "...                                                                 ...   \n",
       "                246_UCR_Anomaly_tilt12755mtable                     270   \n",
       "                247_UCR_Anomaly_tilt12755mtable                      80   \n",
       "                248_UCR_Anomaly_weallwalk                             5   \n",
       "                249_UCR_Anomaly_weallwalk                            30   \n",
       "                250_UCR_Anomaly_weallwalk                             6   \n",
       "\n",
       "                                                  max_anomaly_length  \\\n",
       "collection_name dataset_name                                           \n",
       "KDD-TSAD        001_UCR_Anomaly_DISTORTED1sddb40                 620   \n",
       "                002_UCR_Anomaly_DISTORTED2sddb40                 300   \n",
       "                003_UCR_Anomaly_DISTORTED3sddb40                 300   \n",
       "                004_UCR_Anomaly                                  200   \n",
       "                004_UCR_Anomaly_DISTORTEDBIDMC1                  200   \n",
       "...                                                              ...   \n",
       "                246_UCR_Anomaly_tilt12755mtable                  270   \n",
       "                247_UCR_Anomaly_tilt12755mtable                   80   \n",
       "                248_UCR_Anomaly_weallwalk                          5   \n",
       "                249_UCR_Anomaly_weallwalk                         30   \n",
       "                250_UCR_Anomaly_weallwalk                          6   \n",
       "\n",
       "                                                         mean       stddev  \\\n",
       "collection_name dataset_name                                                 \n",
       "KDD-TSAD        001_UCR_Anomaly_DISTORTED1sddb40   -27.144590   175.478213   \n",
       "                002_UCR_Anomaly_DISTORTED2sddb40   -25.141412   173.018208   \n",
       "                003_UCR_Anomaly_DISTORTED3sddb40   -24.828451   172.602470   \n",
       "                004_UCR_Anomaly                   1130.949099  9315.219071   \n",
       "                004_UCR_Anomaly_DISTORTEDBIDMC1   1130.949099  9315.219071   \n",
       "...                                                       ...          ...   \n",
       "                246_UCR_Anomaly_tilt12755mtable   5041.727730   889.323740   \n",
       "                247_UCR_Anomaly_tilt12755mtable   4978.535763   876.777608   \n",
       "                248_UCR_Anomaly_weallwalk           -1.185222     0.398741   \n",
       "                249_UCR_Anomaly_weallwalk           -1.185866     0.392685   \n",
       "                250_UCR_Anomaly_weallwalk           -1.185361     0.394378   \n",
       "\n",
       "                                                     trend  \\\n",
       "collection_name dataset_name                                 \n",
       "KDD-TSAD        001_UCR_Anomaly_DISTORTED1sddb40  no trend   \n",
       "                002_UCR_Anomaly_DISTORTED2sddb40  no trend   \n",
       "                003_UCR_Anomaly_DISTORTED3sddb40  no trend   \n",
       "                004_UCR_Anomaly                   no trend   \n",
       "                004_UCR_Anomaly_DISTORTEDBIDMC1   no trend   \n",
       "...                                                    ...   \n",
       "                246_UCR_Anomaly_tilt12755mtable   no trend   \n",
       "                247_UCR_Anomaly_tilt12755mtable   no trend   \n",
       "                248_UCR_Anomaly_weallwalk         no trend   \n",
       "                249_UCR_Anomaly_weallwalk         no trend   \n",
       "                250_UCR_Anomaly_weallwalk         no trend   \n",
       "\n",
       "                                                           stationarity  \\\n",
       "collection_name dataset_name                                              \n",
       "KDD-TSAD        001_UCR_Anomaly_DISTORTED1sddb40  difference_stationary   \n",
       "                002_UCR_Anomaly_DISTORTED2sddb40  difference_stationary   \n",
       "                003_UCR_Anomaly_DISTORTED3sddb40  difference_stationary   \n",
       "                004_UCR_Anomaly                   difference_stationary   \n",
       "                004_UCR_Anomaly_DISTORTEDBIDMC1   difference_stationary   \n",
       "...                                                                 ...   \n",
       "                246_UCR_Anomaly_tilt12755mtable          not_stationary   \n",
       "                247_UCR_Anomaly_tilt12755mtable          not_stationary   \n",
       "                248_UCR_Anomaly_weallwalk                not_stationary   \n",
       "                249_UCR_Anomaly_weallwalk                not_stationary   \n",
       "                250_UCR_Anomaly_weallwalk                not_stationary   \n",
       "\n",
       "                                                  period_size  \n",
       "collection_name dataset_name                                   \n",
       "KDD-TSAD        001_UCR_Anomaly_DISTORTED1sddb40          NaN  \n",
       "                002_UCR_Anomaly_DISTORTED2sddb40          NaN  \n",
       "                003_UCR_Anomaly_DISTORTED3sddb40          NaN  \n",
       "                004_UCR_Anomaly                           NaN  \n",
       "                004_UCR_Anomaly_DISTORTEDBIDMC1           NaN  \n",
       "...                                                       ...  \n",
       "                246_UCR_Anomaly_tilt12755mtable           NaN  \n",
       "                247_UCR_Anomaly_tilt12755mtable           NaN  \n",
       "                248_UCR_Anomaly_weallwalk                 NaN  \n",
       "                249_UCR_Anomaly_weallwalk                 NaN  \n",
       "                250_UCR_Anomaly_weallwalk                 NaN  \n",
       "\n",
       "[265 rows x 20 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.refresh()\n",
    "dm.df().loc[(slice(dataset_collection_name,dataset_collection_name), slice(None))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datasets = find_datasets(source_folder)\n",
    "[d.name for d in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = datasets[3]\n",
    "data = np.genfromtxt(f)\n",
    "anomaly = tuple(int(idx) for idx in f.stem.split(\"_\")[-2:])\n",
    "split_at = int(f.stem.split(\"_\")[-3])\n",
    "df = pd.DataFrame(data, columns=[\"value\"])\n",
    "df[\"is_anomaly\"] = 0\n",
    "df.loc[range(anomaly[0], anomaly[1]), \"is_anomaly\"] = 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.plot()\n",
    "plt.gca().add_patch(matplotlib.patches.Rectangle(\n",
    "    (anomaly[0], data.min()),\n",
    "    anomaly[1]-anomaly[0],\n",
    "    data.max()-data.min(),\n",
    "    color=\"yellow\", alpha=0.75\n",
    "))\n",
    "plt.xlim(anomaly[0]-1500, anomaly[1]+1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_dataset(datasets[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeeval.utils.metrics import Metric\n",
    "\n",
    "def print_metrics(labels, scores):\n",
    "    metrics = []\n",
    "    for metric in [Metric.ROC_AUC, Metric.PR_AUC, Metric.AVERAGE_PRECISION]:\n",
    "        try:\n",
    "            metrics.append((metric.name, metric(labels, scores)))\n",
    "        except Exception as e:\n",
    "            print(f\"Error in calculation of {metric.name}: {repr(e)}\")\n",
    "    display(pd.DataFrame(metrics, columns=[\"Name\", \"Value\"]).set_index(\"Name\").T)\n",
    "\n",
    "# load datasets and ground truth\n",
    "f = datasets[1]\n",
    "data = np.genfromtxt(f)\n",
    "anomaly = tuple(int(idx) for idx in f.stem.split(\"_\")[-2:])\n",
    "split_at = int(f.stem.split(\"_\")[-3])\n",
    "df = pd.DataFrame(data, columns=[\"value\"])\n",
    "df[\"is_anomaly\"] = 0\n",
    "df.loc[range(anomaly[0], anomaly[1]), \"is_anomaly\"] = 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.linspace(0, 1, num=df.shape[0], dtype=np.float_)\n",
    "print_metrics(df[\"is_anomaly\"], scores)\n",
    "\n",
    "plt.plot(scores, label=\"scores\")\n",
    "plt.plot(df[\"is_anomaly\"], label=\"labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros(df.shape[0])\n",
    "scores[split_at:] = np.linspace(0, 1, num=df.shape[0]-split_at, dtype=np.float_)\n",
    "\n",
    "print_metrics(df[\"is_anomaly\"], scores)\n",
    "plt.plot(scores, label=\"scores\")\n",
    "plt.plot(df[\"is_anomaly\"], label=\"labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.linspace(0, 0.9, num=df.shape[0], dtype=np.float_)\n",
    "scores[range(anomaly[0]-5, anomaly[1]+5)] = 1\n",
    "\n",
    "print_metrics(df[\"is_anomaly\"], scores)\n",
    "plt.plot(scores, label=\"scores\")\n",
    "plt.plot(df[\"is_anomaly\"], label=\"labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros(df.shape[0])\n",
    "scores[split_at:] = np.linspace(0, 0.9, num=df.shape[0]-split_at, dtype=np.float_)\n",
    "scores[range(anomaly[0]-5, anomaly[1]+5)] = 1\n",
    "\n",
    "print_metrics(df[\"is_anomaly\"], scores)\n",
    "plt.plot(scores, label=\"scores\")\n",
    "plt.plot(df[\"is_anomaly\"], label=\"labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros(df.shape[0])\n",
    "scores[split_at:] = np.linspace(0, 0.9, num=df.shape[0]-split_at, dtype=np.float_)\n",
    "scores[10100:10400] = 1\n",
    "scores[range(anomaly[0]-5, anomaly[1]+5)] = 1\n",
    "\n",
    "print_metrics(df[\"is_anomaly\"], scores)\n",
    "plt.plot(scores, label=\"scores\")\n",
    "plt.plot(df[\"is_anomaly\"], label=\"labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
